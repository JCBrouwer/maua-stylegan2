__main__ train:106                                :2187.1 Mb     if args.distributed:
torchvision.transforms.functional to_tensor:89    :4469.1 Mb     elif pic.mode == 'I;16':
selectors __init__:348                            :4469.1 Mb         super().__init__()
torch.utils.data._utils.fetch <listcomp>:44       :4469.1 Mb             data = [self.dataset[idx] for idx in possibly_batched_index]
sre_compile compile:775                           :4469.1 Mb     groupindex = p.pattern.groupdict
importlib._bootstrap _handle_fromlist:1032        :4469.1 Mb             elif not hasattr(module, x):
torchvision.transforms.transforms __call__:67     :4469.1 Mb             img = t(img)
torch.utils.data._utils.collate default_collate:48:4469.1 Mb         out = None
threading __init__:806                            :4469.1 Mb         _dangling.add(self)
models.stylegan2 forward:250                      :4433.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
torch.utils.data._utils.collate default_collate:53:2231.1 Mb             storage = elem.storage()._new_shared(numel)
threading daemon:1137                             :2231.1 Mb         self._daemonic = daemonic
sre_compile compile:783                           :2231.1 Mb         groupindex, tuple(indexgroup)
models.stylegan2 forward:250                      :2229.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
selectors register:352                            :2229.1 Mb         key = super().register(fileobj, events, data)
importlib._bootstrap _handle_fromlist:1019        :2229.1 Mb     if hasattr(module, '__path__'):
torchvision.transforms.transforms __call__:67     :2229.1 Mb             img = t(img)
torchvision.transforms.transforms __call__:66     :2229.1 Mb         for t in self.transforms:
dataset __getitem__:36                            :2229.1 Mb                 break
importlib._bootstrap __exit__:320                 :4453.1 Mb             spec = self._spec
selectors register:355                            :4453.1 Mb             poller_events |= self._EVENT_READ
torch.overrides has_torch_function:1087           :4453.1 Mb         for a in relevant_args
importlib._bootstrap _handle_fromlist:1044        :4453.1 Mb     return module
multiprocessing.util debug:49                     :4453.1 Mb     if _logger:
torch.nn.modules.module _call_impl:730            :4453.1 Mb                 self._forward_hooks.values()):
torch.tensor wrapped:24                           :4453.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
multiprocessing.queues put:85                     :4453.1 Mb         with self._notempty:
models.stylegan2 forward:235                      :4433.1 Mb             out = F.conv_transpose2d(inputs, weight, padding=0, stride=2, groups=batch)
importlib._bootstrap __exit__:329                 :6621.1 Mb             self._spec._initializing = False
multiprocessing.util __init__:193                 :6621.1 Mb             self._weakref = weakref.ref(obj, self)
torchvision.transforms.transforms forward:647     :6621.1 Mb         return img
multiprocessing.connection wait:920               :6621.1 Mb             while True:
torch.nn.modules.module _call_impl:724            :6621.1 Mb         if torch._C._get_tracing_state():
torch.overrides <genexpr>:1087                    :6621.1 Mb         for a in relevant_args
torch.overrides <genexpr>:1084                    :6621.1 Mb         type(a) is not torch.Tensor and
multiprocessing.queues _start_thread:161          :6621.1 Mb             target=Queue._feed,
models.stylegan2 forward:250                      :6601.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
multiprocessing.queues _start_thread:181          :4417.1 Mb         self._close = Finalize(
torchvision.transforms.transforms __call__:67     :4417.1 Mb             img = t(img)
torch.tensor <genexpr>:24                         :4417.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
selectors select:415                              :4417.1 Mb             fd_event_list = self._selector.poll(timeout)
torchvision.transforms.functional normalize:281   :4417.1 Mb         mean = mean.view(-1, 1, 1)
torchvision.transforms.functional normalize:282   :4417.1 Mb     if std.ndim == 1:
threading __init__:788                            :4417.1 Mb             kwargs = {}
importlib._bootstrap release:105                  :2231.1 Mb         with self.lock:
models.stylegan2 forward:250                      :2229.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
multiprocessing.queues _start_thread:182          :2229.1 Mb             self, Queue._finalize_close,
torch.nn.modules.module _call_impl:716            :2229.1 Mb         for hook in itertools.chain(
torch.tensor <genexpr>:24                         :2229.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
selectors select:418                              :2229.1 Mb         for fd, event in fd_event_list:
torchvision.transforms.functional normalize:282   :2229.1 Mb     if std.ndim == 1:
torchvision.transforms.functional normalize:283   :2229.1 Mb         std = std.view(-1, 1, 1)
threading __init__:789                            :2229.1 Mb         self._target = target
threading __init__:793                            :4453.1 Mb         if daemon is not None:
torch.nn.modules.module _call_impl:729            :4453.1 Mb                 _global_forward_hooks.values(),
torch.nn.modules.module _call_impl:728            :4453.1 Mb         for hook in itertools.chain(
multiprocessing.util __init__:193                 :4453.1 Mb             self._weakref = weakref.ref(obj, self)
torchvision.transforms.transforms forward:615     :4453.1 Mb         if torch.rand(1) < self.p:
torch.overrides <genexpr>:1087                    :4453.1 Mb         for a in relevant_args
selectors select:425                              :4453.1 Mb             key = self._key_from_fd(fd)
importlib._bootstrap release:112                  :4453.1 Mb                 if self.waiters:
models.stylegan2 forward:235                      :4433.1 Mb             out = F.conv_transpose2d(inputs, weight, padding=0, stride=2, groups=batch)
dataset __getitem__:27                            :8815.1 Mb         while True:
threading __init__:799                            :8815.1 Mb         self._started = Event()
torch.utils.data._utils.fetch <listcomp>:44       :8815.1 Mb             data = [self.dataset[idx] for idx in possibly_batched_index]
multiprocessing.queues put:89                     :8815.1 Mb             self._notempty.notify()
torch.overrides has_torch_function:1084           :8815.1 Mb         type(a) is not torch.Tensor and
torch.nn.modules.module _call_impl:729            :8815.1 Mb                 _global_forward_hooks.values(),
multiprocessing.connection wait:923               :8815.1 Mb                     return [key.fileobj for (key, events) in ready]
dataset __getitem__:36                            :8815.1 Mb                 break
models.stylegan2 forward:250                      :8797.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
dataset __getitem__:36                            :6613.1 Mb                 break
models.stylegan2 forward:250                      :2233.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
torch.utils.data._utils.worker get_worker_info:109:2233.1 Mb     return _worker_info
threading notify:350                              :2233.1 Mb             return
torchvision.transforms.functional to_tensor:63    :2233.1 Mb     if not(F_pil._is_pil_image(pic) or _is_numpy(pic)):
multiprocessing.queues get:108                    :2233.1 Mb                 res = self._recv_bytes()
torch.tensor wrapped:26                           :2233.1 Mb         try:
threading __init__:228                            :2233.1 Mb         except AttributeError:
torch.nn.modules.module _call_impl:724            :2233.1 Mb         if torch._C._get_tracing_state():
dataset __getitem__:41                            :2233.1 Mb         img = self.transform(img)
torch.utils.data._utils.collate default_collate:53:4463.1 Mb             storage = elem.storage()._new_shared(numel)
torch.utils.data._utils.worker is_alive:56        :4463.1 Mb                 self.manager_dead = os.getppid() != self.manager_pid
torchvision.transforms.functional to_tensor:69    :4463.1 Mb     if isinstance(pic, np.ndarray):
threading __init__:233                            :4463.1 Mb             pass
torchvision.transforms.functional_pil hflip:51    :4463.1 Mb     if not _is_pil_image(img):
importlib._bootstrap _handle_fromlist:1044        :4463.1 Mb     return module
multiprocessing.connection recv_bytes:214         :4463.1 Mb         if maxlength is not None and maxlength < 0:
torch.nn.modules.module _call_impl:718            :4463.1 Mb                 self._forward_pre_hooks.values()):
models.stylegan2 forward:235                      :4445.1 Mb             out = F.conv_transpose2d(inputs, weight, padding=0, stride=2, groups=batch)
threading __init__:801                            :6639.1 Mb         self._initialized = True
torch.overrides <genexpr>:1087                    :6639.1 Mb         for a in relevant_args
torchvision.transforms.functional to_tensor:98    :6639.1 Mb     img = img.view(pic.size[1], pic.size[0], len(pic.getbands()))
multiprocessing.connection _recv:380              :6639.1 Mb             n = len(chunk)
torch.storage _new_shared:132                     :6639.1 Mb         if cls.is_cuda:
multiprocessing.queues get:102                    :6639.1 Mb                 if block:
torch.tensor <genexpr>:24                         :6639.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
torch.nn.modules.module _call_impl:734            :6639.1 Mb         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):
models.stylegan2 forward:250                      :6621.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
torch.nn.modules.module _call_impl:729            :4427.1 Mb                 _global_forward_hooks.values(),
models.stylegan2 forward:250                      :4427.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
threading is_set:509                              :4427.1 Mb         return self._flag
multiprocessing.connection _poll:414              :4427.1 Mb         r = wait([self], timeout)
importlib._bootstrap _handle_fromlist:1020        :4427.1 Mb         for x in fromlist:
multiprocessing.connection _recv_bytes:411        :4427.1 Mb         return self._recv(size)
torchvision.transforms.functional to_tensor:66    :4427.1 Mb     if _is_numpy(pic) and not _is_numpy_image(pic):
torch.overrides <genexpr>:1087                    :4427.1 Mb         for a in relevant_args
multiprocessing.queues put:82                     :4427.1 Mb         if not self._sem.acquire(block, timeout):
multiprocessing.connection _recv:379              :6621.1 Mb             chunk = read(handle, remaining)
torchvision.transforms.functional to_tensor:89    :6621.1 Mb     elif pic.mode == 'I;16':
torchvision.transforms.functional to_tensor:102   :6621.1 Mb         return img.float().div(255)
torch.nn.modules.module _call_impl:728            :6621.1 Mb         for hook in itertools.chain(
multiprocessing.queues _start_thread:156          :6621.1 Mb         debug('Queue._start_thread()')
torch.nn.modules.module _call_impl:716            :6621.1 Mb         for hook in itertools.chain(
threading start:847                               :6621.1 Mb         if self._started.is_set():
selectors __init__:349                            :6621.1 Mb         self._selector = self._selector_cls()
models.stylegan2 forward:235                      :6621.1 Mb             out = F.conv_transpose2d(inputs, weight, padding=0, stride=2, groups=batch)
models.stylegan2 forward:250                      :4427.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
threading daemon:1129                             :4427.1 Mb         return self._daemonic
torch.tensor <genexpr>:24                         :4427.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
torchvision.transforms.functional normalize:276   :4427.1 Mb     mean = torch.as_tensor(mean, dtype=dtype, device=tensor.device)
selectors register:355                            :4427.1 Mb             poller_events |= self._EVENT_READ
torch.utils.data._utils.worker _worker_loop:191   :4427.1 Mb             idx, index = r
multiprocessing.util __init__:193                 :4427.1 Mb             self._weakref = weakref.ref(obj, self)
torch.overrides <genexpr>:1084                    :4427.1 Mb         type(a) is not torch.Tensor and
torchvision.transforms.transforms forward:616     :4427.1 Mb             return F.hflip(img)
torchvision.transforms.functional to_tensor:63    :6749.1 Mb     if not(F_pil._is_pil_image(pic) or _is_numpy(pic)):
torch.tensor wrapped:26                           :6749.1 Mb         try:
threading __init__:234                            :6749.1 Mb         try:
selectors select:419                              :6749.1 Mb             events = 0
torchvision.transforms.transforms __call__:67     :6749.1 Mb             img = t(img)
torch.nn.modules.module _call_impl:728            :6749.1 Mb         for hook in itertools.chain(
multiprocessing.util __init__:200                 :6749.1 Mb         self._key = (exitpriority, next(_finalizer_counter))
torch.nn.modules.module _call_impl:730            :6749.1 Mb                 self._forward_hooks.values()):
models.stylegan2 forward:250                      :6749.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
models.stylegan2 forward:250                      :4427.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
_weakrefset add:84                                :4427.1 Mb         self.data.add(ref(item, self._remove))
torchvision.transforms.functional to_tensor:96    :4427.1 Mb         img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))
torchvision.transforms.functional to_tensor:69    :4427.1 Mb     if isinstance(pic, np.ndarray):
threading notify:350                              :4427.1 Mb             return
torch.nn.modules.module _call_impl:734            :4427.1 Mb         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):
torch.tensor <genexpr>:24                         :4427.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
dataset __getitem__:30                            :4427.1 Mb                     key = f"{self.resolution}-{str(index).zfill(5)}".encode("utf-8")
multiprocessing.connection wait:923               :4427.1 Mb                     return [key.fileobj for (key, events) in ready]
torchvision.transforms.functional to_tensor:102   :9041.1 Mb         return img.float().div(255)
threading start:852                               :9041.1 Mb             _start_new_thread(self._bootstrap, ())
multiprocessing.queues get:102                    :9041.1 Mb                 if block:
multiprocessing.connection _recv:375              :9041.1 Mb         buf = io.BytesIO()
torch.utils.data._utils.collate <listcomp>:52     :9041.1 Mb             numel = sum([x.numel() for x in batch])
torch.nn.modules.module _call_impl:718            :9041.1 Mb                 self._forward_pre_hooks.values()):
torch.nn.modules.module _call_impl:730            :9041.1 Mb                 self._forward_hooks.values()):
importlib._bootstrap _handle_fromlist:1019        :9041.1 Mb     if hasattr(module, '__path__'):
models.stylegan2 forward:250                      :9041.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
models.stylegan2 forward:250                      :4427.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
torchvision.transforms.transforms forward:615     :4427.1 Mb         if torch.rand(1) < self.p:
importlib._bootstrap _handle_fromlist:1044        :4427.1 Mb     return module
torchvision.transforms.functional normalize:272   :4427.1 Mb     if not inplace:
torchvision.transforms.functional normalize:277   :4427.1 Mb     std = torch.as_tensor(std, dtype=dtype, device=tensor.device)
multiprocessing.connection _recv_bytes:408        :4427.1 Mb         size, = struct.unpack("!i", buf.getvalue())
selectors __init__:211                            :4427.1 Mb         self._fd_to_key = {}
torch.overrides <genexpr>:1087                    :4427.1 Mb         for a in relevant_args
multiprocessing.queues _start_thread:174          :4427.1 Mb             self._jointhread = Finalize(
torch.tensor wrapped:23                           :6731.1 Mb         from torch.overrides import has_torch_function, handle_torch_function
torchvision.transforms.functional to_tensor:93    :6731.1 Mb     elif pic.mode == '1':
importlib._bootstrap _handle_fromlist:1019        :6731.1 Mb     if hasattr(module, '__path__'):
torch.nn.modules.module _call_impl:727            :6731.1 Mb             result = self.forward(*input, **kwargs)
threading __init__:236                            :6731.1 Mb         except AttributeError:
multiprocessing.connection _check_readable:139    :6731.1 Mb         if not self._readable:
multiprocessing.connection <listcomp>:923         :6731.1 Mb                     return [key.fileobj for (key, events) in ready]
torch.multiprocessing get_sharing_strategy:70     :6731.1 Mb     return _sharing_strategy
models.stylegan2 forward:250                      :6731.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
models.stylegan2 forward:250                      :4427.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
multiprocessing.connection _check_readable:139    :4427.1 Mb         if not self._readable:
torch.overrides <genexpr>:1084                    :4427.1 Mb         type(a) is not torch.Tensor and
torch.tensor wrapped:23                           :4427.1 Mb         from torch.overrides import has_torch_function, handle_torch_function
multiprocessing.queues put:87                     :4427.1 Mb                 self._start_thread()
torch.overrides <genexpr>:1087                    :4427.1 Mb         for a in relevant_args
torch.nn.modules.module _call_impl:717            :4427.1 Mb                 _global_forward_pre_hooks.values(),
threading daemon:1133                             :4427.1 Mb         if not self._initialized:
multiprocessing.connection wait:915               :4427.1 Mb                 selector.register(obj, selectors.EVENT_READ)
selectors select:419                              :6727.1 Mb             events = 0
torchvision.transforms.functional hflip:458       :6727.1 Mb         return F_pil.hflip(img)
multiprocessing.util __init__:203                 :6727.1 Mb         _finalizer_registry[self._key] = self
dataset __getitem__:34                            :6727.1 Mb                 buffer = BytesIO(img_bytes)
multiprocessing.synchronize is_set:328            :6727.1 Mb         with self._cond:
torch.nn.modules.module _call_impl:729            :6727.1 Mb                 _global_forward_hooks.values(),
threading __init__:232                            :6727.1 Mb         except AttributeError:
torch.nn.modules.module _call_impl:729            :6727.1 Mb                 _global_forward_hooks.values(),
torch.nn.modules.module __getattr__:769           :6727.1 Mb                 return _parameters[name]
torch.nn.modules.module __getattr__:769           :4423.1 Mb                 return _parameters[name]
_weakrefset add:84                                :4423.1 Mb         self.data.add(ref(item, self._remove))
importlib._bootstrap _handle_fromlist:1019        :4423.1 Mb     if hasattr(module, '__path__'):
torch.utils.data._utils.fetch <listcomp>:44       :4423.1 Mb             data = [self.dataset[idx] for idx in possibly_batched_index]
torchvision.transforms.transforms __call__:104    :4423.1 Mb         return F.to_tensor(pic)
torchvision.transforms.functional to_tensor:81    :4423.1 Mb     if accimage is not None and isinstance(pic, accimage.Image):
multiprocessing.connection <listcomp>:923         :4423.1 Mb                     return [key.fileobj for (key, events) in ready]
multiprocessing.queues put:88                     :4423.1 Mb             self._buffer.append(obj)
torch.utils.data._utils.collate default_collate:49:4423.1 Mb         if torch.utils.data.get_worker_info() is not None:
torch.utils.data._utils.collate <listcomp>:52     :9033.1 Mb             numel = sum([x.numel() for x in batch])
multiprocessing.connection _poll:415              :9033.1 Mb         return bool(r)
threading _is_owned:262                           :9033.1 Mb             return True
torchvision.transforms.functional to_tensor:66    :9033.1 Mb     if _is_numpy(pic) and not _is_numpy_image(pic):
torchvision.transforms.functional to_tensor:93    :9033.1 Mb     elif pic.mode == '1':
torch.overrides has_torch_function:1083           :9033.1 Mb     return _is_torch_function_enabled() and any(
threading daemon:1137                             :9033.1 Mb         self._daemonic = daemonic
dataset __getitem__:32                            :9033.1 Mb                     img_bytes = txn.get(key)
torch.nn.modules.module __getattr__:769           :9033.1 Mb                 return _parameters[name]
torch.nn.modules.module __getattr__:769           :4423.1 Mb                 return _parameters[name]
torch.nn.modules.module _call_impl:718            :4423.1 Mb                 self._forward_pre_hooks.values()):
torchvision.transforms.functional to_tensor:101   :4423.1 Mb     if isinstance(img, torch.ByteTensor):
threading wait:549                                :4423.1 Mb         with self._cond:
torchvision.transforms.transforms forward:645     :4423.1 Mb         if torch.rand(1) < self.p:
torch.nn.modules.module _call_impl:729            :4423.1 Mb                 _global_forward_hooks.values(),
torch.utils.data._utils.worker _worker_loop:171   :4423.1 Mb                 r = index_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
multiprocessing.connection _recv:379              :4423.1 Mb             chunk = read(handle, remaining)
torch.multiprocessing get_sharing_strategy:70     :4423.1 Mb     return _sharing_strategy
torch.tensor <genexpr>:24                         :6733.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
torch.utils.data._utils.worker _worker_loop:212   :6733.1 Mb             data_queue.put((idx, data))
torchvision.transforms.transforms __call__:67     :6733.1 Mb             img = t(img)
multiprocessing.queues get:101                    :6733.1 Mb             try:
multiprocessing.connection _recv:378              :6733.1 Mb         while remaining > 0:
torchvision.transforms.functional normalize:272   :6733.1 Mb     if not inplace:
multiprocessing.queues _start_thread:171          :6733.1 Mb         debug('... done self._thread.start()')
torch.nn.modules.module _call_impl:718            :6733.1 Mb                 self._forward_pre_hooks.values()):
torch.nn.modules.module __getattr__:769           :6733.1 Mb                 return _parameters[name]
torch.nn.modules.module __getattr__:769           :4425.1 Mb                 return _parameters[name]
selectors __init__:213                            :4425.1 Mb         self._map = _SelectorMapping(self)
multiprocessing.connection _recv:387              :4425.1 Mb             remaining -= n
multiprocessing.util __init__:200                 :4425.1 Mb         self._key = (exitpriority, next(_finalizer_counter))
torch.nn.modules.module _call_impl:729            :4425.1 Mb                 _global_forward_hooks.values(),
torch.overrides has_torch_function:1084           :4425.1 Mb         type(a) is not torch.Tensor and
multiprocessing.queues _start_thread:164          :4425.1 Mb                   self._on_queue_feeder_error, self._sem),
torch.overrides has_torch_function:1084           :4425.1 Mb         type(a) is not torch.Tensor and
importlib._bootstrap _handle_fromlist:1019        :4425.1 Mb     if hasattr(module, '__path__'):
torch.overrides <genexpr>:1084                    :5587.1 Mb         type(a) is not torch.Tensor and
selectors __init__:349                            :5587.1 Mb         self._selector = self._selector_cls()
multiprocessing.util __init__:203                 :5587.1 Mb         _finalizer_registry[self._key] = self
multiprocessing.connection _recv:388              :5587.1 Mb         return buf
torch.nn.modules.module _call_impl:734            :5587.1 Mb         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):
threading __init__:786                            :5587.1 Mb         assert group is None, "group argument must be None for now"
torch.overrides <genexpr>:1084                    :5587.1 Mb         type(a) is not torch.Tensor and
torch.tensor wrapped:24                           :5587.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
torch.nn.modules.module __getattr__:769           :5587.1 Mb                 return _parameters[name]
torch.overrides has_torch_function:1083           :6693.1 Mb     return _is_torch_function_enabled() and any(
torchvision.transforms.functional to_tensor:63    :6693.1 Mb     if not(F_pil._is_pil_image(pic) or _is_numpy(pic)):
threading __init__:500                            :6693.1 Mb         self._cond = Condition(Lock())
selectors register:240                            :6693.1 Mb         if key.fd in self._fd_to_key:
torchvision.transforms.functional normalize:283   :6693.1 Mb         std = std.view(-1, 1, 1)
torch.nn.modules.module _call_impl:749            :6693.1 Mb         return result
torch.utils.data._utils.worker _worker_loop:193   :6693.1 Mb             if init_exception is not None:
threading _is_owned:258                           :6693.1 Mb         if self._lock.acquire(0):
torch.nn.modules.module __getattr__:769           :6693.1 Mb                 return _parameters[name]
dataset __getitem__:28                            :5589.1 Mb             try:
torch.nn.modules.module __getattr__:769           :5589.1 Mb                 return _parameters[name]
torch.utils.data._utils.worker is_alive:57        :5589.1 Mb             return not self.manager_dead
torch.nn.modules.module _call_impl:734            :5589.1 Mb         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):
dataset __getitem__:36                            :5589.1 Mb                 break
torchvision.transforms.functional to_tensor:98    :5589.1 Mb     img = img.view(pic.size[1], pic.size[0], len(pic.getbands()))
threading __init__:235                            :5589.1 Mb             self._is_owned = lock._is_owned
torch.utils.data._utils.collate <listcomp>:52     :5589.1 Mb             numel = sum([x.numel() for x in batch])
multiprocessing.connection wait:921               :5589.1 Mb                 ready = selector.select(timeout)
threading __init__:236                            :6695.1 Mb         except AttributeError:
torch.utils.data._utils.collate <listcomp>:52     :6695.1 Mb             numel = sum([x.numel() for x in batch])
selectors select:405                              :6695.1 Mb         if timeout is None:
dataset __getitem__:30                            :6695.1 Mb                     key = f"{self.resolution}-{str(index).zfill(5)}".encode("utf-8")
torchvision.transforms.transforms __call__:66     :6695.1 Mb         for t in self.transforms:
torchvision.transforms.transforms __call__:66     :6695.1 Mb         for t in self.transforms:
torch.utils.data._utils.worker _worker_loop:171   :6695.1 Mb                 r = index_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
torchvision.transforms.functional to_tensor:101   :6695.1 Mb     if isinstance(img, torch.ByteTensor):
torch.nn.modules.module __getattr__:769           :6695.1 Mb                 return _parameters[name]
torch.nn.modules.module __getattr__:769           :5593.1 Mb                 return _parameters[name]
multiprocessing.queues _start_thread:167          :5593.1 Mb         self._thread.daemon = True
torchvision.transforms.functional to_tensor:87    :5593.1 Mb     if pic.mode == 'I':
multiprocessing.connection _check_closed:135      :5593.1 Mb         if self._handle is None:
torchvision.transforms.functional normalize:265   :5593.1 Mb     if not isinstance(tensor, torch.Tensor):
selectors select:425                              :5593.1 Mb             key = self._key_from_fd(fd)
importlib._bootstrap _handle_fromlist:1044        :5593.1 Mb     return module
torch.nn.modules.module _call_impl:718            :5593.1 Mb                 self._forward_pre_hooks.values()):
torch.storage _new_shared:134                     :5593.1 Mb         elif get_sharing_strategy() == 'file_system':
torchvision.transforms.functional to_tensor:91    :7787.1 Mb     elif pic.mode == 'F':
multiprocessing.connection _check_readable:139    :7787.1 Mb         if not self._readable:
selectors _key_from_fd:285                        :7787.1 Mb             return self._fd_to_key[fd]
torchvision.transforms.functional normalize:272   :7787.1 Mb     if not inplace:
torch.tensor <genexpr>:24                         :7787.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
torch.nn.modules.module _call_impl:727            :7787.1 Mb             result = self.forward(*input, **kwargs)
torch.storage _new_shared:137                     :7787.1 Mb             return cls._new_using_fd(size)
threading is_set:509                              :7787.1 Mb         return self._flag
torch.nn.modules.module __getattr__:769           :7787.1 Mb                 return _parameters[name]
torch.nn.modules.module __getattr__:769           :5595.1 Mb                 return _parameters[name]
selectors __enter__:200                           :5595.1 Mb         return self
threading start:849                               :5595.1 Mb         with _active_limbo_lock:
torch.overrides <genexpr>:1087                    :5595.1 Mb         for a in relevant_args
torch.overrides has_torch_function:1083           :5595.1 Mb     return _is_torch_function_enabled() and any(
multiprocessing.connection <listcomp>:923         :5595.1 Mb                     return [key.fileobj for (key, events) in ready]
importlib._bootstrap _handle_fromlist:1044        :5595.1 Mb     return module
torchvision.transforms.transforms __call__:66     :5595.1 Mb         for t in self.transforms:
multiprocessing.queues put:86                     :5595.1 Mb             if self._thread is None:
multiprocessing.connection wait:915               :6693.1 Mb                 selector.register(obj, selectors.EVENT_READ)
threading start:851                               :6693.1 Mb         try:
torch.tensor wrapped:26                           :6693.1 Mb         try:
selectors close:269                               :6693.1 Mb         self._fd_to_key.clear()
torch.overrides has_torch_function:1087           :6693.1 Mb         for a in relevant_args
torch.tensor <genexpr>:24                         :6693.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
torch.nn.modules.module _call_impl:716            :6693.1 Mb         for hook in itertools.chain(
multiprocessing.queues _start_thread:156          :6693.1 Mb         debug('Queue._start_thread()')
torch.nn.modules.module __getattr__:769           :6693.1 Mb                 return _parameters[name]
torch.nn.modules.module __getattr__:769           :5597.1 Mb                 return _parameters[name]
selectors _fileobj_to_fd:41                       :5597.1 Mb     if fd < 0:
torchvision.transforms.functional normalize:276   :5597.1 Mb     mean = torch.as_tensor(mean, dtype=dtype, device=tensor.device)
torch.tensor wrapped:27                           :5597.1 Mb             return f(*args, **kwargs)
threading __init__:788                            :5597.1 Mb             kwargs = {}
multiprocessing.queues _start_thread:174          :5597.1 Mb             self._jointhread = Finalize(
torch.nn.modules.module _call_impl:730            :5597.1 Mb                 self._forward_hooks.values()):
torch.nn.modules.module _call_impl:718            :5597.1 Mb                 self._forward_pre_hooks.values()):
multiprocessing.connection _recv:376              :5597.1 Mb         handle = self._handle
threading __init__:789                            :6697.1 Mb         self._target = target
multiprocessing.queues _start_thread:175          :6697.1 Mb                 self._thread, Queue._finalize_join,
torch.nn.modules.module _call_impl:734            :6697.1 Mb         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):
torch.nn.modules.module _call_impl:724            :6697.1 Mb         if torch._C._get_tracing_state():
multiprocessing.connection _recv:377              :6697.1 Mb         remaining = size
torch.nn.modules.module __getattr__:769           :6697.1 Mb                 return _parameters[name]
selectors register:240                            :6697.1 Mb         if key.fd in self._fd_to_key:
torchvision.transforms.functional normalize:278   :6697.1 Mb     if (std == 0).any():
torchvision.transforms.functional normalize:281   :6697.1 Mb         mean = mean.view(-1, 1, 1)
models.stylegan2 forward:633                      :6955.1 Mb             out = (out + skip) / math.sqrt(2)
torchvision.transforms.functional normalize:277   :6955.1 Mb     std = torch.as_tensor(std, dtype=dtype, device=tensor.device)
torch.utils.data._utils.worker is_alive:56        :6955.1 Mb                 self.manager_dead = os.getppid() != self.manager_pid
torch.tensor wrapped:24                           :6955.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
torch.nn.modules.module _call_impl:728            :6955.1 Mb         for hook in itertools.chain(
multiprocessing.connection _recv:377              :6955.1 Mb         remaining = size
selectors register:235                            :6955.1 Mb         if (not events) or (events & ~(EVENT_READ | EVENT_WRITE)):
torchvision.transforms.transforms forward:226     :6955.1 Mb         return F.normalize(tensor, self.mean, self.std, self.inplace)
multiprocessing.queues _start_thread:177          :6955.1 Mb                 exitpriority=-5
multiprocessing.connection wait:920               :8151.1 Mb             while True:
torchvision.transforms.functional normalize:280   :8151.1 Mb     if mean.ndim == 1:
torchvision.transforms.transforms forward:615     :8125.1 Mb         if torch.rand(1) < self.p:
torch.utils.data._utils.worker _worker_loop:197   :8125.1 Mb                 try:
threading _is_owned:258                           :8125.1 Mb         if self._lock.acquire(0):
torch.overrides <genexpr>:1084                    :8125.1 Mb         type(a) is not torch.Tensor and
selectors register:352                            :8125.1 Mb         key = super().register(fileobj, events, data)
torch.nn.modules.module _call_impl:730            :8125.1 Mb                 self._forward_hooks.values()):
torch.utils.data._utils.fetch fetch:44            :7027.1 Mb             data = [self.dataset[idx] for idx in possibly_batched_index]
torchvision.transforms.transforms forward:617     :7027.1 Mb         return img
selectors _fileobj_lookup:224                     :7027.1 Mb         try:
torch.utils.data._utils.fetch <listcomp>:44       :8125.1 Mb             data = [self.dataset[idx] for idx in possibly_batched_index]
torch.nn.modules.module _call_impl:728            :8125.1 Mb         for hook in itertools.chain(
selectors _fileobj_lookup:225                     :8123.1 Mb             return _fileobj_to_fd(fileobj)
dataset __getitem__:27                            :10319.1Mb         while True:
torch.nn.modules.module _call_impl:729            :10319.1Mb                 _global_forward_hooks.values(),
selectors _fileobj_to_fd:33                       :10319.1Mb     if isinstance(fileobj, int):
threading notify:350                              :10319.1Mb             return
torch.nn.modules.module _call_impl:728            :10319.1Mb         for hook in itertools.chain(
dataset __getitem__:43                            :10319.1Mb         return img
selectors select:414                              :10319.1Mb         try:
torch.tensor <genexpr>:24                         :10319.1Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
threading __exit__:244                            :9221.1 Mb         return self._lock.__exit__(*args)
torch.nn.modules.module _call_impl:729            :9221.1 Mb                 _global_forward_hooks.values(),
torch.utils.data._utils.fetch <listcomp>:44       :9221.1 Mb             data = [self.dataset[idx] for idx in possibly_batched_index]
selectors select:415                              :9221.1 Mb             fd_event_list = self._selector.poll(timeout)
torch.overrides has_torch_function:1083           :9221.1 Mb     return _is_torch_function_enabled() and any(
dataset __getitem__:29                            :9221.1 Mb                 with self.env.begin(write=False) as txn:
torch.nn.modules.module _call_impl:734            :9221.1 Mb         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):
selectors _fileobj_to_fd:37                       :9221.1 Mb             fd = int(fileobj.fileno())
torch.nn.modules.module _call_impl:730            :7025.1 Mb                 self._forward_hooks.values()):
dataset __getitem__:27                            :7025.1 Mb         while True:
torch.utils.data._utils.worker _worker_loop:213   :7025.1 Mb             del data, idx, index, r  # save memory
selectors select:418                              :7025.1 Mb         for fd, event in fd_event_list:
torch.overrides has_torch_function:1084           :7025.1 Mb         type(a) is not torch.Tensor and
dataset __getitem__:30                            :7025.1 Mb                     key = f"{self.resolution}-{str(index).zfill(5)}".encode("utf-8")
multiprocessing.connection fileno:170             :7025.1 Mb         self._check_closed()
torch.nn.modules.module _call_impl:749            :7025.1 Mb         return result
torch.nn.modules.module _call_impl:734            :8131.1 Mb         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):
dataset __getitem__:28                            :8131.1 Mb             try:
torch.utils.data._utils.worker _worker_loop:169   :8131.1 Mb         while watchdog.is_alive():
selectors select:419                              :8131.1 Mb             events = 0
torch.overrides has_torch_function:1087           :8131.1 Mb         for a in relevant_args
dataset __getitem__:32                            :8131.1 Mb                     img_bytes = txn.get(key)
multiprocessing.connection _check_closed:135      :8131.1 Mb         if self._handle is None:
torchvision.transforms.transforms __call__:66     :8131.1 Mb         for t in self.transforms:
dataset __getitem__:32                            :9235.1 Mb                     img_bytes = txn.get(key)
torch.utils.data._utils.worker is_alive:57        :9235.1 Mb             return not self.manager_dead
torch.overrides <genexpr>:1084                    :9235.1 Mb         type(a) is not torch.Tensor and
selectors select:423                              :9235.1 Mb                 events |= EVENT_READ
selectors _fileobj_to_fd:43                       :9235.1 Mb     return fd
torchvision.transforms.functional to_tensor:63    :9235.1 Mb     if not(F_pil._is_pil_image(pic) or _is_numpy(pic)):
dataset __getitem__:43                            :9235.1 Mb         return img
dataset __getitem__:36                            :9235.1 Mb                 break
dataset __getitem__:35                            :8129.1 Mb                 img = Image.open(buffer)
torch.utils.data._utils.worker _worker_loop:171   :8129.1 Mb                 r = index_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
selectors _key_from_fd:284                        :8129.1 Mb         try:
torch.overrides <genexpr>:1084                    :8129.1 Mb         type(a) is not torch.Tensor and
selectors register:244                            :8129.1 Mb         self._fd_to_key[key.fd] = key
torch.utils.data._utils.fetch fetch:47            :8129.1 Mb         return self.collate_fn(data)
torchvision.transforms.functional_pil _is_pil_image:19:8129.1 Mb         return isinstance(img, Image.Image)
torchvision.transforms.transforms __call__:66     :8129.1 Mb         for t in self.transforms:
torchvision.transforms.functional_pil _is_pil_image:19:9241.1 Mb         return isinstance(img, Image.Image)
torch.utils.data._utils.collate <listcomp>:52     :9241.1 Mb             numel = sum([x.numel() for x in batch])
torch.tensor wrapped:23                           :9241.1 Mb         from torch.overrides import has_torch_function, handle_torch_function
torchvision.transforms.functional to_tensor:93    :9241.1 Mb     elif pic.mode == '1':
selectors register:363                            :9241.1 Mb         return key
torch.nn.modules.module _call_impl:727            :9241.1 Mb             result = self.forward(*input, **kwargs)
multiprocessing.connection poll:255               :9241.1 Mb         self._check_closed()
multiprocessing.connection <listcomp>:923         :9241.1 Mb                     return [key.fileobj for (key, events) in ready]
torch.nn.modules.module _call_impl:728            :8103.1 Mb         for hook in itertools.chain(
torch.tensor wrapped:24                           :8103.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
multiprocessing.connection wait:918               :8103.1 Mb                 deadline = time.monotonic() + timeout
multiprocessing.connection _check_readable:139    :8103.1 Mb         if not self._readable:
torchvision.transforms.functional to_tensor:98    :8103.1 Mb     img = img.view(pic.size[1], pic.size[0], len(pic.getbands()))
importlib._bootstrap _handle_fromlist:1019        :8103.1 Mb     if hasattr(module, '__path__'):
torch.storage _new_shared:131                     :8103.1 Mb         from torch.multiprocessing import get_sharing_strategy
selectors close:270                               :8103.1 Mb         self._map = None
importlib._bootstrap _handle_fromlist:1028        :10313.1Mb             elif x == '*':
multiprocessing.connection _check_closed:135      :10313.1Mb         if self._handle is None:
torch.tensor <genexpr>:24                         :10313.1Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
torchvision.transforms.transforms __call__:66     :10313.1Mb         for t in self.transforms:
torch.overrides has_torch_function:1087           :10313.1Mb         for a in relevant_args
torchvision.transforms.transforms __call__:66     :10313.1Mb         for t in self.transforms:
selectors select:412                              :10313.1Mb             timeout = math.ceil(timeout * 1e3)
selectors __init__:211                            :10313.1Mb         self._fd_to_key = {}
torch.overrides <genexpr>:1087                    :8005.1 Mb         for a in relevant_args
torch.nn.modules.module _call_impl:718            :8005.1 Mb                 self._forward_pre_hooks.values()):
selectors select:418                              :8005.1 Mb         for fd, event in fd_event_list:
torch.storage _new_shared:134                     :8005.1 Mb         elif get_sharing_strategy() == 'file_system':
selectors __enter__:200                           :8005.1 Mb         return self
multiprocessing.connection _recv_bytes:407        :8005.1 Mb         buf = self._recv(4)
torch.overrides <genexpr>:1087                    :8005.1 Mb         for a in relevant_args
torchvision.transforms.functional_pil _is_pil_image:19:8005.1 Mb         return isinstance(img, Image.Image)
torch.nn.modules.module _call_impl:724            :6843.1 Mb         if torch._C._get_tracing_state():
selectors select:419                              :6843.1 Mb             events = 0
torch.multiprocessing get_sharing_strategy:70     :6843.1 Mb     return _sharing_strategy
multiprocessing.connection wait:914               :6843.1 Mb             for obj in object_list:
multiprocessing.connection _recv:375              :6843.1 Mb         buf = io.BytesIO()
torch.overrides <genexpr>:1084                    :6843.1 Mb         type(a) is not torch.Tensor and
torchvision.transforms.functional to_tensor:66    :6843.1 Mb     if _is_numpy(pic) and not _is_numpy_image(pic):
torch.tensor wrapped:26                           :6843.1 Mb         try:
torch.nn.modules.module _call_impl:734            :7549.1 Mb         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):
torchvision.transforms.transforms __call__:67     :7549.1 Mb             img = t(img)
multiprocessing.queues put:86                     :7549.1 Mb             if self._thread is None:
selectors select:428                              :7549.1 Mb         return ready
torchvision.transforms.functional normalize:278   :7549.1 Mb     if (std == 0).any():
multiprocessing.connection fileno:170             :7549.1 Mb         self._check_closed()
torchvision.transforms.functional to_tensor:98    :7549.1 Mb     img = img.view(pic.size[1], pic.size[0], len(pic.getbands()))
multiprocessing.connection _recv:388              :7549.1 Mb         return buf
torch.nn.modules.module _call_impl:718            :6843.1 Mb                 self._forward_pre_hooks.values()):
threading notify:345                              :6843.1 Mb         if not self._is_owned():
multiprocessing.connection <listcomp>:923         :6843.1 Mb                     return [key.fileobj for (key, events) in ready]
importlib._bootstrap _handle_fromlist:1044        :6843.1 Mb     return module
selectors _fileobj_to_fd:41                       :6843.1 Mb     if fd < 0:
multiprocessing.connection _recv_bytes:411        :6843.1 Mb         return self._recv(size)
torchvision.transforms.functional to_tensor:102   :6843.1 Mb         return img.float().div(255)
torch.nn.modules.module _call_impl:716            :6843.1 Mb         for hook in itertools.chain(
torch.nn.modules.module _call_impl:728            :7997.1 Mb         for hook in itertools.chain(
torch.tensor wrapped:24                           :7997.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
torchvision.transforms.functional hflip:457       :7997.1 Mb     if not isinstance(img, torch.Tensor):
torch.tensor wrapped:26                           :7997.1 Mb         try:
multiprocessing.synchronize __enter__:230         :7997.1 Mb         return self._lock.__enter__()
multiprocessing.queues get:99                     :7997.1 Mb             if not self._rlock.acquire(block, timeout):
selectors select:413                              :7997.1 Mb         ready = []
multiprocessing.connection _recv:387              :7997.1 Mb             remaining -= n
multiprocessing.queues get:103                    :6843.1 Mb                     timeout = deadline - time.monotonic()
torch.nn.modules.module _call_impl:728            :6843.1 Mb         for hook in itertools.chain(
multiprocessing.synchronize is_set:332            :6843.1 Mb             return False
selectors select:418                              :6843.1 Mb         for fd, event in fd_event_list:
multiprocessing.connection _recv_bytes:408        :6843.1 Mb         size, = struct.unpack("!i", buf.getvalue())
torch.nn.modules.module _call_impl:749            :6843.1 Mb         return result
torch.overrides has_torch_function:1084           :6843.1 Mb         type(a) is not torch.Tensor and
torchvision.transforms.functional_pil _is_pil_image:19:6843.1 Mb         return isinstance(img, Image.Image)
multiprocessing.connection wait:914               :7119.1 Mb             for obj in object_list:
torch.utils.data._utils.worker is_alive:55        :7119.1 Mb             if not self.manager_dead:
torchvision.transforms.functional normalize:265   :7119.1 Mb     if not isinstance(tensor, torch.Tensor):
torch.utils.data._utils.collate default_collate:52:7119.1 Mb             numel = sum([x.numel() for x in batch])
multiprocessing.connection poll:256               :7421.1 Mb         self._check_readable()
torch.multiprocessing get_sharing_strategy:70     :7575.1 Mb     return _sharing_strategy
torch.overrides has_torch_function:1084           :7575.1 Mb         type(a) is not torch.Tensor and
selectors register:244                            :7867.1 Mb         self._fd_to_key[key.fd] = key
torch.autograd backward:132                       :7867.1 Mb         allow_unreachable=True)  # allow_unreachable flag
torch.storage _new_shared:137                     :7867.1 Mb             return cls._new_using_fd(size)
multiprocessing.connection _check_readable:139    :7867.1 Mb         if not self._readable:
torch.overrides has_torch_function:1087           :7867.1 Mb         for a in relevant_args
selectors select:415                              :7867.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7867.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7867.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7867.1 Mb             fd_event_list = self._selector.poll(timeout)
threading notify:353                              :7353.1 Mb             try:
selectors register:358                            :7353.1 Mb         try:
multiprocessing.queues get:105                    :7353.1 Mb                         raise Empty
selectors select:422                              :7353.1 Mb             if event & ~self._EVENT_WRITE:
threading notify:354                              :6249.1 Mb                 all_waiters.remove(waiter)
selectors register:359                            :6247.1 Mb             self._selector.register(key.fd, poller_events)
multiprocessing.queues get:111                    :6247.1 Mb                 self._rlock.release()
selectors select:423                              :6247.1 Mb                 events |= EVENT_READ
torch.nn.modules.module __getattr__:769           :6233.1 Mb                 return _parameters[name]
selectors _fileobj_to_fd:43                       :6759.1 Mb     return fd
multiprocessing.connection _recv:381              :6759.1 Mb             if n == 0:
selectors register:240                            :6759.1 Mb         if key.fd in self._fd_to_key:
multiprocessing.connection wait:917               :6501.1 Mb             if timeout is not None:
torch.autograd grad:204                           :6501.1 Mb         inputs, allow_unused)
torchvision.transforms.functional to_tensor:101   :9317.1 Mb     if isinstance(img, torch.ByteTensor):
torch.utils.data._utils.collate default_collate:55:6757.1 Mb         return torch.stack(batch, 0, out=out)
selectors select:415                              :6757.1 Mb             fd_event_list = self._selector.poll(timeout)
multiprocessing.connection _poll:415              :7909.1 Mb         return bool(r)
multiprocessing.queues get:103                    :7909.1 Mb                     timeout = deadline - time.monotonic()
selectors register:352                            :6757.1 Mb         key = super().register(fileobj, events, data)
selectors select:405                              :6757.1 Mb         if timeout is None:
selectors select:415                              :6505.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :6505.1 Mb             fd_event_list = self._selector.poll(timeout)
torch.autograd grad:204                           :6761.1 Mb         inputs, allow_unused)
selectors __init__:211                            :7017.1 Mb         self._fd_to_key = {}
multiprocessing.queues get:113                    :7017.1 Mb         return _ForkingPickler.loads(res)
multiprocessing.connection wait:922               :7017.1 Mb                 if ready:
torch.autograd backward:132                       :7019.1 Mb         allow_unreachable=True)  # allow_unreachable flag
selectors select:415                              :7019.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7019.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7019.1 Mb             fd_event_list = self._selector.poll(timeout)
torch.tensor wrapped:23                           :7275.1 Mb         from torch.overrides import has_torch_function, handle_torch_function
dataset __getitem__:29                            :7275.1 Mb                 with self.env.begin(write=False) as txn:
selectors select:415                              :7275.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7275.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7275.1 Mb             fd_event_list = self._selector.poll(timeout)
torch.nn.modules.module __getattr__:769           :7277.1 Mb                 return _parameters[name]
selectors select:415                              :6481.1 Mb             fd_event_list = self._selector.poll(timeout)
torch.utils.data._utils.worker is_alive:55        :8677.1 Mb             if not self.manager_dead:
selectors select:415                              :8677.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8677.1 Mb             fd_event_list = self._selector.poll(timeout)
torch.utils.data._utils.worker is_alive:56        :6483.1 Mb                 self.manager_dead = os.getppid() != self.manager_pid
multiprocessing.connection wait:926               :6483.1 Mb                         timeout = deadline - time.monotonic()
selectors __init__:349                            :6483.1 Mb         self._selector = self._selector_cls()
torch.utils.data._utils.worker is_alive:57        :8677.1 Mb             return not self.manager_dead
multiprocessing.connection wait:927               :8677.1 Mb                         if timeout < 0:
selectors __enter__:200                           :8677.1 Mb         return self
multiprocessing.queues get:92                     :6483.1 Mb         if block and timeout is None:
selectors close:269                               :6483.1 Mb         self._fd_to_key.clear()
multiprocessing.queues get:97                     :8677.1 Mb             if block:
selectors close:270                               :8677.1 Mb         self._map = None
multiprocessing.queues get:101                    :6483.1 Mb             try:
selectors _fileobj_lookup:225                     :6483.1 Mb             return _fileobj_to_fd(fileobj)
multiprocessing.queues get:111                    :6483.1 Mb                 self._rlock.release()
selectors _fileobj_to_fd:33                       :10865.1Mb     if isinstance(fileobj, int):
multiprocessing.queues get:103                    :10865.1Mb                     timeout = deadline - time.monotonic()
torch.utils.data._utils.worker _worker_loop:172   :10865.1Mb             except queue.Empty:
selectors select:415                              :10865.1Mb             fd_event_list = self._selector.poll(timeout)
selectors select:418                              :6483.1 Mb         for fd, event in fd_event_list:
torch.utils.data._utils.worker is_alive:57        :6483.1 Mb             return not self.manager_dead
multiprocessing.connection _check_readable:139    :6483.1 Mb         if not self._readable:
multiprocessing.connection fileno:171             :6483.1 Mb         return self._handle
selectors _fileobj_to_fd:41                       :8667.1 Mb     if fd < 0:
multiprocessing.connection wait:922               :8667.1 Mb                 if ready:
torch.utils.data._utils.worker _worker_loop:171   :8667.1 Mb                 r = index_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
multiprocessing.connection _poll:414              :8667.1 Mb         r = wait([self], timeout)
multiprocessing.connection wait:926               :6481.1 Mb                         timeout = deadline - time.monotonic()
selectors register:244                            :6481.1 Mb         self._fd_to_key[key.fd] = key
multiprocessing.queues get:97                     :6481.1 Mb             if block:
selectors __init__:348                            :6481.1 Mb         super().__init__()
multiprocessing.queues get:98                     :8667.1 Mb                 deadline = time.monotonic() + timeout
selectors __init__:211                            :8667.1 Mb         self._fd_to_key = {}
multiprocessing.connection wait:927               :8667.1 Mb                         if timeout < 0:
selectors register:245                            :8667.1 Mb         return key
multiprocessing.queues get:99                     :6481.1 Mb             if not self._rlock.acquire(block, timeout):
selectors __init__:213                            :6481.1 Mb         self._map = _SelectorMapping(self)
multiprocessing.connection wait:928               :6481.1 Mb                             return ready
selectors register:353                            :6481.1 Mb         poller_events = 0
multiprocessing.queues get:101                    :8667.1 Mb             try:
selectors __init__:64                             :8667.1 Mb         self._selector = selector
selectors __exit__:203                            :8667.1 Mb         self.close()
selectors register:354                            :8667.1 Mb         if events & EVENT_READ:
multiprocessing.queues get:103                    :6481.1 Mb                     timeout = deadline - time.monotonic()
selectors __enter__:200                           :6481.1 Mb         return self
selectors close:270                               :6481.1 Mb         self._map = None
selectors register:356                            :6481.1 Mb         if events & EVENT_WRITE:
torch.autograd backward:132                       :6481.1 Mb         allow_unreachable=True)  # allow_unreachable flag
selectors select:415                              :6489.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :6501.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :6735.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :6735.1 Mb             fd_event_list = self._selector.poll(timeout)
op.upfirdn2d forward:119                          :6863.1 Mb             input, kernel, up_x, up_y, down_x, down_y, pad_x0, pad_x1, pad_y0, pad_y1
torchvision.transforms.functional_pil _is_pil_image:19:6927.1 Mb         return isinstance(img, Image.Image)
op.upfirdn2d forward:119                          :7121.1 Mb             input, kernel, up_x, up_y, down_x, down_y, pad_x0, pad_x1, pad_y0, pad_y1
torchvision.transforms.functional to_tensor:91    :7187.1 Mb     elif pic.mode == 'F':
torch.nn.modules.module __getattr__:769           :7393.1 Mb                 return _parameters[name]
selectors select:415                              :7419.1 Mb             fd_event_list = self._selector.poll(timeout)
torchvision.transforms.functional normalize:273   :7515.1 Mb         tensor = tensor.clone()
torchvision.transforms.functional normalize:275   :8069.1 Mb     dtype = tensor.dtype
selectors select:428                              :8069.1 Mb         return ready
torch.autograd backward:132                       :8069.1 Mb         allow_unreachable=True)  # allow_unreachable flag
selectors select:415                              :8069.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8069.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8069.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8069.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8069.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8069.1 Mb             fd_event_list = self._selector.poll(timeout)
