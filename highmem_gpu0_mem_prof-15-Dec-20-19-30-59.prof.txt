__main__ train:106                                :2087.1 Mb     if args.distributed:
torch.utils.data._utils.collate default_collate:54:4353.1 Mb             out = elem.new(storage)
torchvision.transforms.functional to_tensor:69    :4353.1 Mb     if isinstance(pic, np.ndarray):
dataset __getitem__:27                            :4353.1 Mb         while True:
importlib._bootstrap release:112                  :4353.1 Mb                 if self.waiters:
torchvision.transforms.functional_pil _is_pil_image:19:4353.1 Mb         return isinstance(img, Image.Image)
sre_compile _compile:76                           :4353.1 Mb     REPEATING_CODES = _REPEATING_CODES
selectors __init__:211                            :4353.1 Mb         self._fd_to_key = {}
threading is_set:509                              :4353.1 Mb         return self._flag
models.stylegan2 forward:250                      :4333.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
models.stylegan2 forward:250                      :2129.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
sre_parse __getitem__:165                         :2129.1 Mb         if isinstance(index, slice):
torchvision.transforms.functional to_tensor:93    :2129.1 Mb     elif pic.mode == '1':
dataset __getitem__:41                            :2129.1 Mb         img = self.transform(img)
multiprocessing.queues put:87                     :2129.1 Mb                 self._start_thread()
threading wait:550                                :2129.1 Mb             signaled = self._flag
selectors register:235                            :2129.1 Mb         if (not events) or (events & ~(EVENT_READ | EVENT_WRITE)):
torchvision.transforms.functional to_tensor:100   :2129.1 Mb     img = img.permute((2, 0, 1)).contiguous()
dataset __getitem__:41                            :2129.1 Mb         img = self.transform(img)
sre_compile _compile:174                          :4353.1 Mb         elif op in ASSERT_CODES:
torch.overrides has_torch_function:1087           :4353.1 Mb         for a in relevant_args
torch.overrides <genexpr>:1084                    :4353.1 Mb         type(a) is not torch.Tensor and
multiprocessing.util __init__:201                 :4353.1 Mb         self._pid = os.getpid()
torchvision.transforms.functional normalize:277   :4353.1 Mb     std = torch.as_tensor(std, dtype=dtype, device=tensor.device)
threading __init__:796                            :4353.1 Mb             self._daemonic = current_thread().daemon
selectors register:356                            :4353.1 Mb         if events & EVENT_WRITE:
torchvision.transforms.transforms __call__:67     :4353.1 Mb             img = t(img)
models.stylegan2 forward:235                      :4333.1 Mb             out = F.conv_transpose2d(inputs, weight, padding=0, stride=2, groups=batch)
torch.tensor <genexpr>:24                         :6521.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
threading __init__:799                            :6521.1 Mb         self._started = Event()
multiprocessing.connection wait:920               :6521.1 Mb             while True:
sre_compile _compile:90                           :6521.1 Mb     for op, av in pattern:
torchvision.transforms.functional normalize:265   :6521.1 Mb     if not isinstance(tensor, torch.Tensor):
torchvision.transforms.transforms forward:647     :6521.1 Mb         return img
torch.nn.modules.module _call_impl:728            :6521.1 Mb         for hook in itertools.chain(
multiprocessing.util __init__:193                 :6521.1 Mb             self._weakref = weakref.ref(obj, self)
models.stylegan2 forward:250                      :6501.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
torchvision.transforms.transforms __call__:67     :4317.1 Mb             img = t(img)
threading __init__:227                            :4317.1 Mb             self._release_save = lock._release_save
selectors select:415                              :4317.1 Mb             fd_event_list = self._selector.poll(timeout)
torch.nn.modules.module _call_impl:716            :4317.1 Mb         for hook in itertools.chain(
multiprocessing.queues put:89                     :4317.1 Mb             self._notempty.notify()
sre_compile compile:780                           :4317.1 Mb     return _sre.compile(
torchvision.transforms.functional normalize:278   :4317.1 Mb     if (std == 0).any():
models.stylegan2 forward:250                      :2129.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
torch.overrides <genexpr>:1084                    :2129.1 Mb         type(a) is not torch.Tensor and
torch.nn.modules.module _call_impl:716            :2129.1 Mb         for hook in itertools.chain(
selectors select:418                              :2129.1 Mb         for fd, event in fd_event_list:
threading __init__:228                            :2129.1 Mb         except AttributeError:
torch.nn.modules.module _call_impl:717            :2129.1 Mb                 _global_forward_pre_hooks.values(),
threading notify:345                              :2129.1 Mb         if not self._is_owned():
sre_compile compile:781                           :2129.1 Mb         pattern, flags | p.pattern.flags, code,
torch.tensor wrapped:23                           :2129.1 Mb         from torch.overrides import has_torch_function, handle_torch_function
torchvision.transforms.transforms forward:615     :4353.1 Mb         if torch.rand(1) < self.p:
selectors select:425                              :4353.1 Mb             key = self._key_from_fd(fd)
threading __init__:233                            :4353.1 Mb             pass
threading notify:349                              :4353.1 Mb         if not waiters_to_notify:
torch.tensor <genexpr>:24                         :4353.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
enum __and__:842                                  :4353.1 Mb         if not isinstance(other, (self.__class__, int)):
torch.tensor wrapped:23                           :4353.1 Mb         from torch.overrides import has_torch_function, handle_torch_function
torchvision.transforms.functional normalize:283   :4353.1 Mb         std = std.view(-1, 1, 1)
models.stylegan2 forward:235                      :4333.1 Mb             out = F.conv_transpose2d(inputs, weight, padding=0, stride=2, groups=batch)
torch.overrides <genexpr>:1087                    :8715.1 Mb         for a in relevant_args
enum __call__:314                                 :8715.1 Mb         if names is None:  # simple value lookup
torch.overrides has_torch_function:1084           :8715.1 Mb         type(a) is not torch.Tensor and
multiprocessing.connection wait:923               :8715.1 Mb                     return [key.fileobj for (key, events) in ready]
torch.nn.modules.module _call_impl:749            :8715.1 Mb         return result
threading __init__:801                            :8715.1 Mb         self._initialized = True
torch.overrides has_torch_function:1084           :8715.1 Mb         type(a) is not torch.Tensor and
torch.utils.data._utils.worker _worker_loop:170   :8715.1 Mb             try:
models.stylegan2 forward:250                      :8697.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
models.stylegan2 forward:250                      :2133.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
multiprocessing.queues get:108                    :2133.1 Mb                 res = self._recv_bytes()
threading daemon:1135                             :2133.1 Mb         if self._started.is_set():
torch.tensor wrapped:26                           :2133.1 Mb         try:
multiprocessing.queues get:102                    :2133.1 Mb                 if block:
torchvision.transforms.functional normalize:284   :2133.1 Mb     tensor.sub_(mean).div_(std)
importlib._bootstrap __exit__:319                 :2133.1 Mb         try:
torch.tensor wrapped:27                           :2133.1 Mb             return f(*args, **kwargs)
torch.utils.data._utils.collate default_collate:47:2133.1 Mb     if isinstance(elem, torch.Tensor):
torchvision.transforms.functional_pil _is_pil_image:19:4363.1 Mb         return isinstance(img, Image.Image)
threading start:847                               :4363.1 Mb         if self._started.is_set():
multiprocessing.connection _recv_bytes:407        :4363.1 Mb         buf = self._recv(4)
torch.nn.modules.module _call_impl:749            :4363.1 Mb         return result
multiprocessing.connection poll:257               :4363.1 Mb         return self._poll(timeout)
torchvision.transforms.transforms __call__:66     :4363.1 Mb         for t in self.transforms:
importlib._bootstrap __exit__:327                 :4363.1 Mb                 _verbose_message('import {!r} # {!r}', spec.name, spec.loader)
torch.utils.data._utils.collate <listcomp>:52     :4363.1 Mb             numel = sum([x.numel() for x in batch])
models.stylegan2 forward:235                      :4345.1 Mb             out = F.conv_transpose2d(inputs, weight, padding=0, stride=2, groups=batch)
torchvision.transforms.functional to_tensor:81    :6539.1 Mb     if accimage is not None and isinstance(pic, accimage.Image):
multiprocessing.connection wait:915               :6539.1 Mb                 selector.register(obj, selectors.EVENT_READ)
importlib._bootstrap release:105                  :6539.1 Mb         with self.lock:
torch.storage _new_shared:132                     :6539.1 Mb         if cls.is_cuda:
torchvision.transforms.transforms __call__:104    :6539.1 Mb         return F.to_tensor(pic)
dataset __getitem__:35                            :6539.1 Mb                 img = Image.open(buffer)
threading wait:553                                :6539.1 Mb             return signaled
multiprocessing.connection _recv:388              :6539.1 Mb         return buf
models.stylegan2 forward:250                      :6521.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
multiprocessing.queues _start_thread:176          :4327.1 Mb                 [weakref.ref(self._thread)],
models.stylegan2 forward:250                      :4327.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
multiprocessing.connection _recv:378              :4327.1 Mb         while remaining > 0:
torch.nn.modules.module _call_impl:718            :4327.1 Mb                 self._forward_pre_hooks.values()):
selectors _fileobj_to_fd:37                       :4327.1 Mb             fd = int(fileobj.fileno())
multiprocessing.queues put:81                     :4327.1 Mb         assert not self._closed, "Queue {0!r} has been closed".format(self)
importlib._bootstrap cb:178                       :4327.1 Mb                 try:
torchvision.transforms.functional to_tensor:100   :4327.1 Mb     img = img.permute((2, 0, 1)).contiguous()
torchvision.transforms.functional to_tensor:87    :4327.1 Mb     if pic.mode == 'I':
multiprocessing.util __init__:193                 :6521.1 Mb             self._weakref = weakref.ref(obj, self)
multiprocessing.connection _recv:386              :6521.1 Mb             buf.write(chunk)
selectors _fileobj_to_fd:41                       :6521.1 Mb     if fd < 0:
torch.tensor wrapped:23                           :6521.1 Mb         from torch.overrides import has_torch_function, handle_torch_function
multiprocessing.queues put:86                     :6521.1 Mb             if self._thread is None:
importlib._bootstrap _handle_fromlist:1020        :6521.1 Mb         for x in fromlist:
torchvision.transforms.transforms __call__:67     :6521.1 Mb             img = t(img)
torchvision.transforms.functional to_tensor:96    :6521.1 Mb         img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))
models.stylegan2 forward:235                      :6521.1 Mb             out = F.conv_transpose2d(inputs, weight, padding=0, stride=2, groups=batch)
threading daemon:1128                             :4327.1 Mb         assert self._initialized, "Thread.__init__() not called"
models.stylegan2 forward:250                      :4327.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
threading notify:345                              :4327.1 Mb         if not self._is_owned():
selectors select:415                              :4327.1 Mb             fd_event_list = self._selector.poll(timeout)
torch.overrides <genexpr>:1087                    :4327.1 Mb         for a in relevant_args
torchvision.transforms.transforms __call__:67     :4327.1 Mb             img = t(img)
torch.nn.modules.module _call_impl:727            :4327.1 Mb             result = self.forward(*input, **kwargs)
torch.overrides has_torch_function:1084           :4327.1 Mb         type(a) is not torch.Tensor and
torch.utils.data._utils.fetch fetch:43            :4327.1 Mb         if self.auto_collation:
torch.tensor <genexpr>:24                         :6649.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
threading __init__:232                            :6649.1 Mb         except AttributeError:
torch.nn.modules.module _call_impl:717            :6649.1 Mb                 _global_forward_pre_hooks.values(),
torch.nn.modules.module _call_impl:729            :6649.1 Mb                 _global_forward_hooks.values(),
multiprocessing.connection <listcomp>:923         :6649.1 Mb                     return [key.fileobj for (key, events) in ready]
torch.nn.modules.module _call_impl:718            :6649.1 Mb                 self._forward_pre_hooks.values()):
multiprocessing.queues get:97                     :6649.1 Mb             if block:
torch.overrides <genexpr>:1084                    :6649.1 Mb         type(a) is not torch.Tensor and
models.stylegan2 forward:250                      :6649.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
models.stylegan2 forward:250                      :4327.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
multiprocessing.connection recv_bytes:216         :4327.1 Mb         buf = self._recv_bytes(maxlength)
torch.utils.data._utils.collate default_collate:47:4327.1 Mb     if isinstance(elem, torch.Tensor):
torch.overrides has_torch_function:1084           :4327.1 Mb         type(a) is not torch.Tensor and
multiprocessing.connection poll:257               :4327.1 Mb         return self._poll(timeout)
torchvision.transforms.functional_pil _is_pil_image:16:4327.1 Mb     if accimage is not None:
_weakrefset add:82                                :4327.1 Mb         if self._pending_removals:
torchvision.transforms.functional normalize:281   :4327.1 Mb         mean = mean.view(-1, 1, 1)
torch.overrides has_torch_function:1084           :4327.1 Mb         type(a) is not torch.Tensor and
importlib._bootstrap _handle_fromlist:1020        :8941.1 Mb         for x in fromlist:
selectors _fileobj_lookup:225                     :8941.1 Mb             return _fileobj_to_fd(fileobj)
threading start:851                               :8941.1 Mb         try:
torchvision.transforms.transforms __call__:66     :8941.1 Mb         for t in self.transforms:
torchvision.transforms.functional_pil hflip:54    :8941.1 Mb     return img.transpose(Image.FLIP_LEFT_RIGHT)
multiprocessing.connection _recv:375              :8941.1 Mb         buf = io.BytesIO()
torchvision.transforms.functional to_tensor:66    :8941.1 Mb     if _is_numpy(pic) and not _is_numpy_image(pic):
dataset __getitem__:28                            :8941.1 Mb             try:
models.stylegan2 forward:250                      :8941.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
models.stylegan2 forward:250                      :4327.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
selectors register:244                            :4327.1 Mb         self._fd_to_key[key.fd] = key
importlib._bootstrap _handle_fromlist:1044        :4327.1 Mb     return module
multiprocessing.connection _recv:388              :4327.1 Mb         return buf
multiprocessing.util debug:49                     :4327.1 Mb     if _logger:
torchvision.transforms.functional to_tensor:63    :4327.1 Mb     if not(F_pil._is_pil_image(pic) or _is_numpy(pic)):
torch.nn.modules.module _call_impl:716            :4327.1 Mb         for hook in itertools.chain(
multiprocessing.queues put:82                     :4327.1 Mb         if not self._sem.acquire(block, timeout):
torchvision.transforms.functional to_tensor:100   :4327.1 Mb     img = img.permute((2, 0, 1)).contiguous()
torch.utils.data._utils.collate default_collate:46:6631.1 Mb     elem_type = type(elem)
torchvision.transforms.functional hflip:458       :6631.1 Mb         return F_pil.hflip(img)
torch.overrides <genexpr>:1087                    :6631.1 Mb         for a in relevant_args
torch.tensor wrapped:27                           :6631.1 Mb             return f(*args, **kwargs)
multiprocessing.connection poll:256               :6631.1 Mb         self._check_readable()
multiprocessing.connection _recv:386              :6631.1 Mb             buf.write(chunk)
torchvision.transforms.functional normalize:278   :6631.1 Mb     if (std == 0).any():
multiprocessing.queues _start_thread:167          :6631.1 Mb         self._thread.daemon = True
models.stylegan2 forward:250                      :6631.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
models.stylegan2 forward:250                      :4327.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
torch.overrides <genexpr>:1084                    :4327.1 Mb         type(a) is not torch.Tensor and
threading start:850                               :4327.1 Mb             _limbo[self] = self
multiprocessing.connection wait:915               :4327.1 Mb                 selector.register(obj, selectors.EVENT_READ)
importlib._bootstrap _handle_fromlist:1021        :4327.1 Mb             if not isinstance(x, str):
torch.nn.modules.module _call_impl:727            :4327.1 Mb             result = self.forward(*input, **kwargs)
torch.nn.modules.module _call_impl:734            :4327.1 Mb         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):
torchvision.transforms.transforms __call__:104    :4327.1 Mb         return F.to_tensor(pic)
multiprocessing.connection _recv:381              :4327.1 Mb             if n == 0:
torchvision.transforms.transforms forward:645     :6627.1 Mb         if torch.rand(1) < self.p:
torchvision.transforms.functional to_tensor:91    :6627.1 Mb     elif pic.mode == 'F':
threading __init__:796                            :6627.1 Mb             self._daemonic = current_thread().daemon
torch.tensor wrapped:26                           :6627.1 Mb         try:
torchvision.transforms.transforms __call__:67     :6627.1 Mb             img = t(img)
selectors select:420                              :6627.1 Mb             if event & ~self._EVENT_READ:
torch.tensor <genexpr>:24                         :6627.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
multiprocessing.util __init__:201                 :6627.1 Mb         self._pid = os.getpid()
torch.nn.modules.module __getattr__:769           :6627.1 Mb                 return _parameters[name]
threading __exit__:244                            :4323.1 Mb         return self._lock.__exit__(*args)
torch.nn.modules.module __getattr__:769           :4323.1 Mb                 return _parameters[name]
multiprocessing.connection wait:923               :4323.1 Mb                     return [key.fileobj for (key, events) in ready]
torch.tensor <genexpr>:24                         :4323.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
threading __init__:222                            :4323.1 Mb         self.release = lock.release
torch.overrides <genexpr>:1087                    :4323.1 Mb         for a in relevant_args
torch.nn.modules.module _call_impl:718            :4323.1 Mb                 self._forward_pre_hooks.values()):
torch.tensor wrapped:27                           :4323.1 Mb             return f(*args, **kwargs)
torch.nn.modules.module _call_impl:718            :4323.1 Mb                 self._forward_pre_hooks.values()):
torch.overrides <genexpr>:1084                    :8933.1 Mb         type(a) is not torch.Tensor and
torchvision.transforms.transforms forward:647     :8933.1 Mb         return img
torchvision.transforms.functional normalize:265   :8933.1 Mb     if not isinstance(tensor, torch.Tensor):
torch.tensor wrapped:23                           :8933.1 Mb         from torch.overrides import has_torch_function, handle_torch_function
selectors close:270                               :8933.1 Mb         self._map = None
torch.utils.data._utils.worker is_alive:57        :8933.1 Mb             return not self.manager_dead
torchvision.transforms.functional normalize:283   :8933.1 Mb         std = std.view(-1, 1, 1)
threading __init__:230                            :8933.1 Mb         try:
torch.nn.modules.module __getattr__:769           :8933.1 Mb                 return _parameters[name]
torch.nn.modules.module __getattr__:769           :4323.1 Mb                 return _parameters[name]
multiprocessing.connection _recv:378              :4323.1 Mb         while remaining > 0:
torch.tensor wrapped:23                           :4323.1 Mb         from torch.overrides import has_torch_function, handle_torch_function
torch.utils.data._utils.collate default_collate:45:4323.1 Mb     elem = batch[0]
threading __init__:806                            :4323.1 Mb         _dangling.add(self)
torchvision.transforms.transforms __call__:67     :4323.1 Mb             img = t(img)
multiprocessing.connection _check_readable:139    :4323.1 Mb         if not self._readable:
torch.overrides has_torch_function:1083           :4323.1 Mb     return _is_torch_function_enabled() and any(
torch.tensor wrapped:26                           :4323.1 Mb         try:
selectors __init__:213                            :6631.1 Mb         self._map = _SelectorMapping(self)
torch.overrides <genexpr>:1087                    :6631.1 Mb         for a in relevant_args
torch.nn.modules.module _call_impl:734            :6631.1 Mb         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):
multiprocessing.connection _recv:388              :6631.1 Mb         return buf
torch.overrides has_torch_function:1084           :6631.1 Mb         type(a) is not torch.Tensor and
torch.utils.data._utils.collate <listcomp>:52     :6631.1 Mb             numel = sum([x.numel() for x in batch])
threading daemon:1137                             :6631.1 Mb         self._daemonic = daemonic
torch.tensor wrapped:23                           :6631.1 Mb         from torch.overrides import has_torch_function, handle_torch_function
torch.nn.modules.module __getattr__:769           :6631.1 Mb                 return _parameters[name]
torch.nn.modules.module __getattr__:769           :4325.1 Mb                 return _parameters[name]
torch.nn.modules.module _call_impl:749            :4325.1 Mb         return result
torch.nn.modules.module _call_impl:749            :4325.1 Mb         return result
torch.tensor wrapped:26                           :4325.1 Mb         try:
torchvision.transforms.functional to_tensor:91    :4325.1 Mb     elif pic.mode == 'F':
threading wait:550                                :4325.1 Mb             signaled = self._flag
torch.multiprocessing get_sharing_strategy:70     :4325.1 Mb     return _sharing_strategy
multiprocessing.connection _check_closed:135      :4325.1 Mb         if self._handle is None:
multiprocessing.connection recv_bytes:217         :4325.1 Mb         if buf is None:
torchvision.transforms.transforms __call__:68     :5487.1 Mb         return img
torchvision.transforms.transforms __call__:67     :5487.1 Mb             img = t(img)
torchvision.transforms.functional to_tensor:96    :5487.1 Mb         img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))
torchvision.transforms.transforms forward:616     :5487.1 Mb             return F.hflip(img)
threading wait:553                                :5487.1 Mb             return signaled
torch.utils.data._utils.collate default_collate:54:5487.1 Mb             out = elem.new(storage)
selectors _fileobj_to_fd:41                       :5487.1 Mb     if fd < 0:
multiprocessing.queues get:109                    :5487.1 Mb                 self._sem.release()
torch.nn.modules.module __getattr__:769           :5487.1 Mb                 return _parameters[name]
torch.utils.data._utils.worker _worker_loop:193   :6593.1 Mb             if init_exception is not None:
multiprocessing.util __init__:199                 :6593.1 Mb         self._kwargs = kwargs or {}
multiprocessing.connection wait:918               :6593.1 Mb                 deadline = time.monotonic() + timeout
torchvision.transforms.functional normalize:265   :6593.1 Mb     if not isinstance(tensor, torch.Tensor):
torch.nn.modules.module _call_impl:717            :6593.1 Mb                 _global_forward_pre_hooks.values(),
multiprocessing.queues _start_thread:162          :6593.1 Mb             args=(self._buffer, self._notempty, self._send_bytes,
torchvision.transforms.transforms __call__:67     :6593.1 Mb             img = t(img)
torchvision.transforms.functional to_tensor:98    :6593.1 Mb     img = img.view(pic.size[1], pic.size[0], len(pic.getbands()))
torch.nn.modules.module __getattr__:769           :6593.1 Mb                 return _parameters[name]
multiprocessing.util __init__:200                 :5487.1 Mb         self._key = (exitpriority, next(_finalizer_counter))
torch.nn.modules.module __getattr__:769           :5487.1 Mb                 return _parameters[name]
torch.overrides <genexpr>:1084                    :5487.1 Mb         type(a) is not torch.Tensor and
dataset __getitem__:41                            :5487.1 Mb         img = self.transform(img)
threading current_thread:1233                     :5487.1 Mb         return _active[get_ident()]
torch.overrides has_torch_function:1083           :5487.1 Mb     return _is_torch_function_enabled() and any(
torchvision.transforms.functional normalize:272   :5487.1 Mb     if not inplace:
torchvision.transforms.functional to_tensor:98    :5487.1 Mb     img = img.view(pic.size[1], pic.size[0], len(pic.getbands()))
selectors _key_from_fd:284                        :5487.1 Mb         try:
selectors _key_from_fd:285                        :6593.1 Mb             return self._fd_to_key[fd]
multiprocessing.util __init__:203                 :6593.1 Mb         _finalizer_registry[self._key] = self
torch.overrides <genexpr>:1084                    :6593.1 Mb         type(a) is not torch.Tensor and
torchvision.transforms.functional to_tensor:100   :6593.1 Mb     img = img.permute((2, 0, 1)).contiguous()
torchvision.transforms.transforms __call__:67     :6593.1 Mb             img = t(img)
torch.overrides has_torch_function:1087           :6593.1 Mb         for a in relevant_args
threading daemon:1129                             :6593.1 Mb         return self._daemonic
torchvision.transforms.functional normalize:275   :6593.1 Mb     dtype = tensor.dtype
torch.nn.modules.module __getattr__:769           :6593.1 Mb                 return _parameters[name]
selectors close:270                               :5491.1 Mb         self._map = None
torch.nn.modules.module __getattr__:769           :5491.1 Mb                 return _parameters[name]
torchvision.transforms.transforms __call__:66     :5491.1 Mb         for t in self.transforms:
torchvision.transforms.functional normalize:283   :5491.1 Mb         std = std.view(-1, 1, 1)
torch.tensor <genexpr>:24                         :5491.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
torch.utils.data._utils.worker _worker_loop:213   :5491.1 Mb             del data, idx, index, r  # save memory
torch.overrides has_torch_function:1084           :5491.1 Mb         type(a) is not torch.Tensor and
threading __init__:228                            :5491.1 Mb         except AttributeError:
torchvision.transforms.functional normalize:265   :5493.1 Mb     if not isinstance(tensor, torch.Tensor):
multiprocessing.queues get:108                    :7687.1 Mb                 res = self._recv_bytes()
torchvision.transforms.functional normalize:268   :7687.1 Mb     if tensor.ndim < 3:
torch.nn.modules.module _call_impl:716            :7687.1 Mb         for hook in itertools.chain(
torch.overrides has_torch_function:1083           :7687.1 Mb     return _is_torch_function_enabled() and any(
torch.utils.data._utils.worker is_alive:55        :7687.1 Mb             if not self.manager_dead:
torch.overrides <genexpr>:1084                    :7687.1 Mb         type(a) is not torch.Tensor and
torchvision.transforms.functional normalize:285   :7687.1 Mb     return tensor
threading __init__:230                            :7687.1 Mb         try:
torch.nn.modules.module __getattr__:769           :7685.1 Mb                 return _parameters[name]
torch.nn.modules.module __getattr__:769           :5495.1 Mb                 return _parameters[name]
torchvision.transforms.functional normalize:281   :5495.1 Mb         mean = mean.view(-1, 1, 1)
importlib._bootstrap _handle_fromlist:1019        :5495.1 Mb     if hasattr(module, '__path__'):
multiprocessing.queues get:99                     :5495.1 Mb             if not self._rlock.acquire(block, timeout):
dataset __getitem__:43                            :5495.1 Mb         return img
multiprocessing.connection _recv:376              :5495.1 Mb         handle = self._handle
torch.tensor wrapped:27                           :5495.1 Mb             return f(*args, **kwargs)
torch.tensor wrapped:24                           :5495.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
threading __init__:501                            :5495.1 Mb         self._flag = False
threading __init__:800                            :6593.1 Mb         self._is_stopped = False
torchvision.transforms.functional normalize:283   :6593.1 Mb         std = std.view(-1, 1, 1)
torch.tensor wrapped:24                           :6593.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
multiprocessing.queues get:102                    :6593.1 Mb                 if block:
torch.utils.data._utils.fetch fetch:47            :6593.1 Mb         return self.collate_fn(data)
multiprocessing.connection _recv:378              :6593.1 Mb         while remaining > 0:
torch.tensor <genexpr>:24                         :6593.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
torch.nn.modules.module _call_impl:728            :6593.1 Mb         for hook in itertools.chain(
torch.nn.modules.module __getattr__:769           :6593.1 Mb                 return _parameters[name]
torch.nn.modules.module __getattr__:769           :5495.1 Mb                 return _parameters[name]
torch.overrides <genexpr>:1084                    :5495.1 Mb         type(a) is not torch.Tensor and
threading is_set:509                              :5495.1 Mb         return self._flag
multiprocessing.connection wait:913               :5495.1 Mb         with _WaitSelector() as selector:
torch.nn.modules.module _call_impl:717            :5495.1 Mb                 _global_forward_pre_hooks.values(),
torch.overrides <genexpr>:1087                    :5495.1 Mb         for a in relevant_args
torch.utils.data._utils.collate <listcomp>:52     :5495.1 Mb             numel = sum([x.numel() for x in batch])
torchvision.transforms.transforms __call__:68     :5495.1 Mb         return img
multiprocessing.connection _recv_bytes:409        :5495.1 Mb         if maxsize is not None and size > maxsize:
multiprocessing.queues _start_thread:169          :6595.1 Mb         debug('doing self._thread.start()')
torch.tensor wrapped:27                           :6595.1 Mb             return f(*args, **kwargs)
torch.nn.modules.module _call_impl:724            :6595.1 Mb         if torch._C._get_tracing_state():
selectors __init__:211                            :6595.1 Mb         self._fd_to_key = {}
torch.tensor wrapped:26                           :6595.1 Mb         try:
torch.utils.data._utils.collate default_collate:53:6595.1 Mb             storage = elem.storage()._new_shared(numel)
torch.utils.data._utils.fetch <listcomp>:44       :6595.1 Mb             data = [self.dataset[idx] for idx in possibly_batched_index]
torch.nn.modules.module __getattr__:769           :6595.1 Mb                 return _parameters[name]
multiprocessing.connection _recv:375              :6597.1 Mb         buf = io.BytesIO()
torch.nn.modules.module __getattr__:769           :6865.1 Mb                 return _parameters[name]
torch.overrides has_torch_function:1087           :6865.1 Mb         for a in relevant_args
selectors close:270                               :6865.1 Mb         self._map = None
threading __init__:232                            :6865.1 Mb         except AttributeError:
multiprocessing.queues get:101                    :6865.1 Mb             try:
torch.overrides <genexpr>:1084                    :6865.1 Mb         type(a) is not torch.Tensor and
torch.utils.data._utils.worker is_alive:57        :6865.1 Mb             return not self.manager_dead
torchvision.transforms.functional normalize:276   :6865.1 Mb     mean = torch.as_tensor(mean, dtype=dtype, device=tensor.device)
torch.nn.modules.module _call_impl:717            :6865.1 Mb                 _global_forward_pre_hooks.values(),
selectors _fileobj_to_fd:33                       :8083.1 Mb     if isinstance(fileobj, int):
torch.utils.data._utils.collate <listcomp>:52     :8083.1 Mb             numel = sum([x.numel() for x in batch])
torch.overrides <genexpr>:1087                    :8083.1 Mb         for a in relevant_args
threading __enter__:241                           :8083.1 Mb         return self._lock.__enter__()
torchvision.transforms.functional_pil _is_pil_image:16:8083.1 Mb     if accimage is not None:
selectors _fileobj_to_fd:43                       :8083.1 Mb     return fd
multiprocessing.connection _recv:387              :8083.1 Mb             remaining -= n
torchvision.transforms.transforms __call__:68     :8067.1 Mb         return img
torch.utils.data._utils.collate <listcomp>:52     :6969.1 Mb             numel = sum([x.numel() for x in batch])
torch.overrides <genexpr>:1084                    :6969.1 Mb         type(a) is not torch.Tensor and
threading wait:550                                :6969.1 Mb             signaled = self._flag
torchvision.transforms.functional_pil _is_pil_image:19:6969.1 Mb         return isinstance(img, Image.Image)
selectors register:240                            :6969.1 Mb         if key.fd in self._fd_to_key:
multiprocessing.connection _recv:378              :6969.1 Mb         while remaining > 0:
torch.utils.data._utils.collate <listcomp>:52     :8067.1 Mb             numel = sum([x.numel() for x in batch])
torch.overrides <genexpr>:1087                    :8067.1 Mb         for a in relevant_args
threading wait:551                                :8067.1 Mb             if not signaled:
selectors register:244                            :8067.1 Mb         self._fd_to_key[key.fd] = key
torchvision.transforms.functional to_tensor:66    :8067.1 Mb     if _is_numpy(pic) and not _is_numpy_image(pic):
multiprocessing.connection _recv:388              :8067.1 Mb         return buf
multiprocessing.connection _check_closed:135      :6969.1 Mb         if self._handle is None:
torch.storage _new_shared:131                     :6969.1 Mb         from torch.multiprocessing import get_sharing_strategy
torch.tensor wrapped:26                           :6969.1 Mb         try:
threading __exit__:244                            :6969.1 Mb         return self._lock.__exit__(*args)
selectors register:353                            :6969.1 Mb         poller_events = 0
torchvision.transforms.functional to_tensor:69    :6969.1 Mb     if isinstance(pic, np.ndarray):
multiprocessing.connection recv_bytes:219         :6969.1 Mb         return buf.getvalue()
dataset __getitem__:28                            :6969.1 Mb             try:
multiprocessing.connection fileno:171             :8067.1 Mb         return self._handle
multiprocessing.queues _start_thread:171          :9161.1 Mb         debug('... done self._thread.start()')
dataset __getitem__:29                            :9161.1 Mb                 with self.env.begin(write=False) as txn:
selectors register:354                            :9161.1 Mb         if events & EVENT_READ:
torch.tensor wrapped:27                           :9161.1 Mb             return f(*args, **kwargs)
multiprocessing.queues get:109                    :9161.1 Mb                 self._sem.release()
torchvision.transforms.functional to_tensor:81    :9161.1 Mb     if accimage is not None and isinstance(pic, accimage.Image):
selectors _fileobj_to_fd:41                       :9161.1 Mb     if fd < 0:
importlib._bootstrap _handle_fromlist:1020        :9161.1 Mb         for x in fromlist:
multiprocessing.queues _start_thread:173          :8071.1 Mb         if not self._joincancelled:
selectors register:356                            :8071.1 Mb         if events & EVENT_WRITE:
torchvision.transforms.functional to_tensor:89    :8071.1 Mb     elif pic.mode == 'I;16':
torch.nn.modules.module _call_impl:728            :8071.1 Mb         for hook in itertools.chain(
dataset __getitem__:32                            :8071.1 Mb                     img_bytes = txn.get(key)
selectors register:240                            :8071.1 Mb         if key.fd in self._fd_to_key:
importlib._bootstrap _handle_fromlist:1021        :8071.1 Mb             if not isinstance(x, str):
multiprocessing.queues get:113                    :8071.1 Mb         return _ForkingPickler.loads(res)
torch.nn.modules.module _call_impl:749            :9175.1 Mb         return result
multiprocessing.util __init__:187                 :9175.1 Mb         if (exitpriority is not None) and not isinstance(exitpriority,int):
selectors register:354                            :9175.1 Mb         if events & EVENT_READ:
importlib._bootstrap _handle_fromlist:1044        :9175.1 Mb     return module
multiprocessing.synchronize is_set:328            :9175.1 Mb         with self._cond:
multiprocessing.connection wait:917               :9175.1 Mb             if timeout is not None:
dataset __getitem__:41                            :9175.1 Mb         img = self.transform(img)
torchvision.transforms.functional to_tensor:98    :9175.1 Mb     img = img.view(pic.size[1], pic.size[0], len(pic.getbands()))
multiprocessing.connection wait:914               :8053.1 Mb             for obj in object_list:
torchvision.transforms.functional_pil _is_pil_image:19:8053.1 Mb         return isinstance(img, Image.Image)
torch.utils.data._utils.collate default_collate:55:8053.1 Mb         return torch.stack(batch, 0, out=out)
multiprocessing.util __init__:200                 :8053.1 Mb         self._key = (exitpriority, next(_finalizer_counter))
selectors select:412                              :8053.1 Mb             timeout = math.ceil(timeout * 1e3)
torchvision.transforms.transforms __call__:67     :8053.1 Mb             img = t(img)
multiprocessing.synchronize __exit__:98           :8053.1 Mb         return self._semlock.__exit__(*args)
torch.nn.modules.module _call_impl:724            :8053.1 Mb         if torch._C._get_tracing_state():
multiprocessing.connection wait:921               :9199.1 Mb                 ready = selector.select(timeout)
multiprocessing.queues put:85                     :9199.1 Mb         with self._notempty:
multiprocessing.queues _start_thread:182          :9199.1 Mb             self, Queue._finalize_close,
selectors select:418                              :9199.1 Mb         for fd, event in fd_event_list:
torch.utils.data._utils.worker _worker_loop:198   :9199.1 Mb                     data = fetcher.fetch(index)
torch.nn.modules.module _call_impl:724            :9199.1 Mb         if torch._C._get_tracing_state():
importlib._bootstrap _handle_fromlist:1019        :9199.1 Mb     if hasattr(module, '__path__'):
torchvision.transforms.functional to_tensor:87    :9199.1 Mb     if pic.mode == 'I':
selectors select:422                              :8093.1 Mb             if event & ~self._EVENT_WRITE:
torch.utils.data._utils.fetch <listcomp>:44       :8093.1 Mb             data = [self.dataset[idx] for idx in possibly_batched_index]
torchvision.transforms.functional normalize:265   :8093.1 Mb     if not isinstance(tensor, torch.Tensor):
torch.tensor <genexpr>:24                         :8093.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
torchvision.transforms.functional to_tensor:93    :8093.1 Mb     elif pic.mode == '1':
selectors select:413                              :8093.1 Mb         ready = []
multiprocessing.queues put:89                     :8093.1 Mb             self._notempty.notify()
multiprocessing.util __init__:192                 :8093.1 Mb         if obj is not None:
torch.overrides <genexpr>:1084                    :10303.1Mb         type(a) is not torch.Tensor and
dataset __getitem__:32                            :10303.1Mb                     img_bytes = txn.get(key)
threading notify:348                              :10303.1Mb         waiters_to_notify = _deque(_islice(all_waiters, n))
selectors select:420                              :10303.1Mb             if event & ~self._EVENT_READ:
multiprocessing.util __init__:200                 :10303.1Mb         self._key = (exitpriority, next(_finalizer_counter))
torchvision.transforms.functional to_tensor:101   :10303.1Mb     if isinstance(img, torch.ByteTensor):
selectors select:427                              :10303.1Mb                 ready.append((key, events & key.events))
torchvision.transforms.functional normalize:276   :10303.1Mb     mean = torch.as_tensor(mean, dtype=dtype, device=tensor.device)
threading notify:352                              :9141.1 Mb             waiter.release()
selectors select:425                              :9141.1 Mb             key = self._key_from_fd(fd)
multiprocessing.queues put:88                     :9141.1 Mb             self._buffer.append(obj)
torch.overrides <genexpr>:1087                    :9141.1 Mb         for a in relevant_args
multiprocessing.connection wait:922               :9141.1 Mb                 if ready:
torch.tensor wrapped:23                           :9141.1 Mb         from torch.overrides import has_torch_function, handle_torch_function
torchvision.transforms.transforms __call__:67     :9141.1 Mb             img = t(img)
dataset __getitem__:36                            :9141.1 Mb                 break
threading notify:354                              :6769.1 Mb                 all_waiters.remove(waiter)
selectors _key_from_fd:285                        :6769.1 Mb             return self._fd_to_key[fd]
multiprocessing.connection <listcomp>:923         :6769.1 Mb                     return [key.fileobj for (key, events) in ready]
threading notify:345                              :6769.1 Mb         if not self._is_owned():
torch.tensor wrapped:26                           :6769.1 Mb         try:
torch.nn.modules.module _call_impl:717            :6769.1 Mb                 _global_forward_pre_hooks.values(),
importlib._bootstrap _handle_fromlist:1044        :6769.1 Mb     return module
torchvision.transforms.transforms __call__:66     :6769.1 Mb         for t in self.transforms:
torchvision.transforms.transforms __call__:67     :7475.1 Mb             img = t(img)
multiprocessing.connection recv_bytes:213         :7475.1 Mb         self._check_readable()
selectors close:269                               :7475.1 Mb         self._fd_to_key.clear()
torch.overrides <genexpr>:1084                    :7475.1 Mb         type(a) is not torch.Tensor and
multiprocessing.queues get:92                     :7475.1 Mb         if block and timeout is None:
importlib._bootstrap _handle_fromlist:1019        :7475.1 Mb     if hasattr(module, '__path__'):
torchvision.transforms.functional normalize:275   :7475.1 Mb     dtype = tensor.dtype
torch.utils.data._utils.worker _worker_loop:169   :7475.1 Mb         while watchdog.is_alive():
multiprocessing.queues get:108                    :6769.1 Mb                 res = self._recv_bytes()
multiprocessing.connection recv_bytes:216         :6769.1 Mb         buf = self._recv_bytes(maxlength)
torch.nn.modules.module _call_impl:718            :6769.1 Mb                 self._forward_pre_hooks.values()):
multiprocessing.queues get:99                     :6769.1 Mb             if not self._rlock.acquire(block, timeout):
torch.utils.data._utils.worker is_alive:57        :6769.1 Mb             return not self.manager_dead
torch.tensor wrapped:26                           :6769.1 Mb         try:
torchvision.transforms.functional normalize:278   :6769.1 Mb     if (std == 0).any():
torch.tensor <genexpr>:24                         :6769.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
selectors _fileobj_lookup:224                     :7923.1 Mb         try:
selectors __enter__:200                           :7923.1 Mb         return self
torch.nn.modules.module _call_impl:728            :7923.1 Mb         for hook in itertools.chain(
torch.utils.data._utils.worker get_worker_info:109:7923.1 Mb     return _worker_info
multiprocessing.connection _recv:387              :7923.1 Mb             remaining -= n
torch.nn.modules.module _call_impl:727            :7923.1 Mb             result = self.forward(*input, **kwargs)
torchvision.transforms.functional_pil _is_pil_image:16:7923.1 Mb     if accimage is not None:
multiprocessing.connection _recv:378              :7923.1 Mb         while remaining > 0:
selectors register:238                            :6769.1 Mb         key = SelectorKey(fileobj, self._fileobj_lookup(fileobj), events, data)
torchvision.transforms.transforms __call__:66     :6769.1 Mb         for t in self.transforms:
torch.utils.data._utils.collate default_collate:53:6769.1 Mb             storage = elem.storage()._new_shared(numel)
multiprocessing.queues get:109                    :6769.1 Mb                 self._sem.release()
multiprocessing.connection _recv:387              :6769.1 Mb             remaining -= n
torch.tensor wrapped:24                           :6769.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
multiprocessing.connection _check_closed:135      :6769.1 Mb         if self._handle is None:
torch.nn.modules.module _call_impl:729            :6769.1 Mb                 _global_forward_hooks.values(),
torch.overrides <genexpr>:1087                    :7035.1 Mb         for a in relevant_args
torch.utils.data._utils.collate <listcomp>:52     :7035.1 Mb             numel = sum([x.numel() for x in batch])
selectors register:238                            :7035.1 Mb         key = SelectorKey(fileobj, self._fileobj_lookup(fileobj), events, data)
dataset __getitem__:43                            :7035.1 Mb         return img
torchvision.transforms.functional_pil _is_pil_image:19:7035.1 Mb         return isinstance(img, Image.Image)
torchvision.transforms.functional to_tensor:66    :7743.1 Mb     if _is_numpy(pic) and not _is_numpy_image(pic):
importlib._bootstrap _handle_fromlist:1020        :7743.1 Mb         for x in fromlist:
selectors register:355                            :7743.1 Mb             poller_events |= self._EVENT_READ
torch.nn.modules.module _call_impl:749            :7743.1 Mb         return result
torch.utils.data._utils.collate default_collate:55:7743.1 Mb         return torch.stack(batch, 0, out=out)
torch.autograd backward:132                       :7743.1 Mb         allow_unreachable=True)  # allow_unreachable flag
selectors select:415                              :7743.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7743.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7743.1 Mb             fd_event_list = self._selector.poll(timeout)
multiprocessing.queues get:98                     :6179.1 Mb                 deadline = time.monotonic() + timeout
selectors register:352                            :6179.1 Mb         key = super().register(fileobj, events, data)
torch.utils.data._utils.worker _worker_loop:170   :6179.1 Mb             try:
selectors select:423                              :6179.1 Mb                 events |= EVENT_READ
multiprocessing.queues get:99                     :5013.1 Mb             if not self._rlock.acquire(block, timeout):
selectors register:235                            :5013.1 Mb         if (not events) or (events & ~(EVENT_READ | EVENT_WRITE)):
torch.utils.data._utils.worker _worker_loop:171   :5013.1 Mb                 r = index_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
selectors select:425                              :5013.1 Mb             key = self._key_from_fd(fd)
torch.nn.modules.module __getattr__:769           :4999.1 Mb                 return _parameters[name]
selectors select:415                              :5003.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :5003.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:413                              :5841.1 Mb         ready = []
torch.utils.data._utils.worker _worker_loop:172   :6609.1 Mb             except queue.Empty:
torch.utils.data._utils.worker _worker_loop:186   :6609.1 Mb             elif done_event.is_set() or iteration_end:
selectors __exit__:203                            :6609.1 Mb         self.close()
selectors select:414                              :6609.1 Mb         try:
torch.autograd grad:204                           :6097.1 Mb         inputs, allow_unused)
torchvision.transforms.functional normalize:275   :9169.1 Mb     dtype = tensor.dtype
torch.utils.data._utils.worker is_alive:55        :8657.1 Mb             if not self.manager_dead:
selectors _fileobj_to_fd:36                       :6353.1 Mb         try:
selectors _fileobj_to_fd:37                       :7505.1 Mb             fd = int(fileobj.fileno())
multiprocessing.queues get:97                     :6957.1 Mb             if block:
selectors __init__:213                            :5805.1 Mb         self._map = _SelectorMapping(self)
selectors _fileobj_lookup:224                     :6125.1 Mb         try:
selectors register:245                            :5867.1 Mb         return key
selectors register:358                            :5291.1 Mb         try:
selectors select:415                              :6267.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:422                              :6781.1 Mb             if event & ~self._EVENT_WRITE:
torch.autograd grad:204                           :7037.1 Mb         inputs, allow_unused)
selectors select:425                              :7293.1 Mb             key = self._key_from_fd(fd)
selectors select:415                              :7293.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7293.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7293.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7293.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7293.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7293.1 Mb             fd_event_list = self._selector.poll(timeout)
torch.nn.modules.module __getattr__:769           :7295.1 Mb                 return _parameters[name]
multiprocessing.connection wait:927               :5401.1 Mb                         if timeout < 0:
multiprocessing.queues get:99                     :7339.1 Mb             if not self._rlock.acquire(block, timeout):
selectors __enter__:200                           :5145.1 Mb         return self
multiprocessing.connection wait:914               :7339.1 Mb             for obj in object_list:
selectors _fileobj_to_fd:43                       :5145.1 Mb     return fd
selectors select:415                              :5145.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :5145.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors register:244                            :7339.1 Mb         self._fd_to_key[key.fd] = key
selectors select:418                              :7339.1 Mb         for fd, event in fd_event_list:
selectors select:428                              :7339.1 Mb         return ready
multiprocessing.connection wait:927               :5145.1 Mb                         if timeout < 0:
selectors register:358                            :5145.1 Mb         try:
multiprocessing.connection wait:928               :7339.1 Mb                             return ready
selectors register:359                            :7339.1 Mb             self._selector.register(key.fd, poller_events)
multiprocessing.connection _poll:415              :5147.1 Mb         return bool(r)
multiprocessing.connection wait:918               :5147.1 Mb                 deadline = time.monotonic() + timeout
multiprocessing.queues get:111                    :5147.1 Mb                 self._rlock.release()
torch.utils.data._utils.worker _worker_loop:172   :9527.1 Mb             except queue.Empty:
multiprocessing.queues get:111                    :9527.1 Mb                 self._rlock.release()
multiprocessing.connection wait:921               :9527.1 Mb                 ready = selector.select(timeout)
selectors select:415                              :9527.1 Mb             fd_event_list = self._selector.poll(timeout)
multiprocessing.connection wait:927               :5147.1 Mb                         if timeout < 0:
torch.utils.data._utils.worker _worker_loop:171   :5147.1 Mb                 r = index_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
torch.utils.data._utils.worker _worker_loop:170   :5147.1 Mb             try:
multiprocessing.queues get:97                     :7333.1 Mb             if block:
selectors __exit__:203                            :7333.1 Mb         self.close()
multiprocessing.queues get:92                     :7333.1 Mb         if block and timeout is None:
multiprocessing.queues get:101                    :5145.1 Mb             try:
multiprocessing.connection _poll:415              :5145.1 Mb         return bool(r)
multiprocessing.queues get:99                     :5145.1 Mb             if not self._rlock.acquire(block, timeout):
multiprocessing.queues get:102                    :7331.1 Mb                 if block:
multiprocessing.queues get:105                    :7331.1 Mb                         raise Empty
multiprocessing.queues get:101                    :7331.1 Mb             try:
multiprocessing.connection poll:255               :5145.1 Mb         self._check_closed()
multiprocessing.queues get:104                    :5145.1 Mb                     if not self._poll(timeout):
torch.utils.data._utils.worker _worker_loop:173   :5145.1 Mb                 continue
multiprocessing.connection poll:256               :7331.1 Mb         self._check_readable()
multiprocessing.connection _check_closed:135      :7331.1 Mb         if self._handle is None:
torch.utils.data._utils.worker is_alive:55        :7331.1 Mb             if not self.manager_dead:
multiprocessing.connection _poll:414              :5145.1 Mb         r = wait([self], timeout)
torch.autograd backward:132                       :5145.1 Mb         allow_unreachable=True)  # allow_unreachable flag
multiprocessing.connection poll:257               :5145.1 Mb         return self._poll(timeout)
torch.utils.data._utils.worker _worker_loop:170   :5145.1 Mb             try:
op.upfirdn2d forward:119                          :5429.1 Mb             input, kernel, up_x, up_y, down_x, down_y, pad_x0, pad_x1, pad_y0, pad_y1
models.stylegan2 forward:633                      :5813.1 Mb             out = (out + skip) / math.sqrt(2)
op.upfirdn2d forward:119                          :6071.1 Mb             input, kernel, up_x, up_y, down_x, down_y, pad_x0, pad_x1, pad_y0, pad_y1
op.upfirdn2d forward:119                          :6347.1 Mb             input, kernel, up_x, up_y, down_x, down_y, pad_x0, pad_x1, pad_y0, pad_y1
torch.autograd backward:132                       :7507.1 Mb         allow_unreachable=True)  # allow_unreachable flag
selectors select:415                              :7507.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7507.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7507.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7507.1 Mb             fd_event_list = self._selector.poll(timeout)
torch.nn.modules.module _call_impl:729            :7799.1 Mb                 _global_forward_hooks.values(),
torch.autograd backward:132                       :7799.1 Mb         allow_unreachable=True)  # allow_unreachable flag
selectors select:415                              :7799.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7799.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7799.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7799.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7799.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7799.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7799.1 Mb             fd_event_list = self._selector.poll(timeout)
augment random_apply_affine:324                   :8275.1 Mb         [(w_o + 2 * p_ux1) / w_p - 1, (h_o + 2 * p_uy1) / h_p - 1], device=grid.device
torch.overrides has_torch_function:1087           :8275.1 Mb         for a in relevant_args
selectors select:415                              :8275.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8275.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8275.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8275.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8275.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8275.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8275.1 Mb             fd_event_list = self._selector.poll(timeout)
torch.nn.functional grid_sample:3391              :8983.1 Mb     return torch.grid_sampler(input, grid, mode_enum, padding_mode_enum, align_corners)
selectors _fileobj_to_fd:37                       :8983.1 Mb             fd = int(fileobj.fileno())
selectors select:415                              :8983.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors __init__:348                            :9691.1 Mb         super().__init__()
torch.autograd backward:132                       :9691.1 Mb         allow_unreachable=True)  # allow_unreachable flag
selectors select:415                              :9691.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :9691.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :9691.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :9691.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :9691.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :9691.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :9691.1 Mb             fd_event_list = self._selector.poll(timeout)
torch.nn.functional grid_sample:3391              :10517.1Mb     return torch.grid_sampler(input, grid, mode_enum, padding_mode_enum, align_corners)
threading __enter__:241                           :10517.1Mb         return self._lock.__enter__()
torch.utils.data._utils.worker _worker_loop:170   :10517.1Mb             try:
torchvision.transforms.transforms __call__:66     :10517.1Mb         for t in self.transforms:
selectors select:415                              :10517.1Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :10517.1Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :10517.1Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :10517.1Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :10517.1Mb             fd_event_list = self._selector.poll(timeout)
