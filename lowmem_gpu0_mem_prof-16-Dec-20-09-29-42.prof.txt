__main__ train:106                                :2187.1 Mb     if args.distributed:
sre_compile _code:611                             :4469.1 Mb     return code
importlib._bootstrap _handle_fromlist:1044        :4469.1 Mb     return module
threading wait:549                                :4469.1 Mb         with self._cond:
dataset __getitem__:36                            :4469.1 Mb                 break
torchvision.transforms.functional to_tensor:96    :4469.1 Mb         img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))
multiprocessing.queues _start_thread:156          :4469.1 Mb         debug('Queue._start_thread()')
torchvision.transforms.functional to_tensor:96    :4469.1 Mb         img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))
selectors __init__:64                             :4469.1 Mb         self._selector = selector
models.stylegan2 forward:250                      :4433.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
selectors register:238                            :2231.1 Mb         key = SelectorKey(fileobj, self._fileobj_lookup(fileobj), events, data)
torch.nn.modules.module _call_impl:724            :2231.1 Mb         if torch._C._get_tracing_state():
multiprocessing.queues _start_thread:164          :2231.1 Mb                   self._on_queue_feeder_error, self._sem),
importlib._bootstrap _handle_fromlist:1028        :2231.1 Mb             elif x == '*':
sre_compile compile:782                           :2231.1 Mb         p.pattern.groups-1,
torch.nn.modules.module _call_impl:716            :2231.1 Mb         for hook in itertools.chain(
models.stylegan2 forward:250                      :2229.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
multiprocessing.queues _start_thread:173          :2229.1 Mb         if not self._joincancelled:
torch.overrides <genexpr>:1087                    :2229.1 Mb         for a in relevant_args
torch.tensor wrapped:23                           :4453.1 Mb         from torch.overrides import has_torch_function, handle_torch_function
torch.overrides has_torch_function:1083           :4453.1 Mb     return _is_torch_function_enabled() and any(
multiprocessing.connection wait:914               :4453.1 Mb             for obj in object_list:
threading __init__:221                            :4453.1 Mb         self.acquire = lock.acquire
torchvision.transforms.functional normalize:276   :4453.1 Mb     mean = torch.as_tensor(mean, dtype=dtype, device=tensor.device)
torch.nn.modules.module _call_impl:729            :4453.1 Mb                 _global_forward_hooks.values(),
multiprocessing.util __init__:197                 :4453.1 Mb         self._callback = callback
importlib._bootstrap __exit__:321                 :4453.1 Mb             if any(arg is not None for arg in args):
models.stylegan2 forward:235                      :4433.1 Mb             out = F.conv_transpose2d(inputs, weight, padding=0, stride=2, groups=batch)
torch.nn.modules.module _call_impl:717            :6621.1 Mb                 _global_forward_pre_hooks.values(),
multiprocessing.queues put:89                     :6621.1 Mb             self._notempty.notify()
torch.overrides has_torch_function:1087           :6621.1 Mb         for a in relevant_args
importlib._bootstrap __exit__:329                 :6621.1 Mb             self._spec._initializing = False
torch.tensor wrapped:26                           :6621.1 Mb         try:
selectors select:413                              :6621.1 Mb         ready = []
threading __init__:232                            :6621.1 Mb         except AttributeError:
torch.tensor <genexpr>:24                         :6621.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
models.stylegan2 forward:250                      :6601.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
torch.tensor wrapped:26                           :2231.1 Mb         try:
threading notify:349                              :2231.1 Mb         if not waiters_to_notify:
importlib._bootstrap __exit__:152                 :2231.1 Mb         self._lock.release()
selectors select:422                              :2231.1 Mb             if event & ~self._EVENT_WRITE:
threading __init__:238                            :2231.1 Mb         self._waiters = _deque()
torch.overrides <genexpr>:1084                    :2231.1 Mb         type(a) is not torch.Tensor and
importlib._bootstrap _handle_fromlist:1044        :2231.1 Mb     return module
torchvision.transforms.functional normalize:284   :2231.1 Mb     tensor.sub_(mean).div_(std)
models.stylegan2 forward:250                      :2229.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
torch.utils.data._utils.worker is_alive:56        :4453.1 Mb                 self.manager_dead = os.getppid() != self.manager_pid
importlib._bootstrap release:110                  :4453.1 Mb             if self.count == 0:
selectors select:427                              :4453.1 Mb                 ready.append((key, events & key.events))
_weakrefset add:82                                :4453.1 Mb         if self._pending_removals:
torch.overrides has_torch_function:1087           :4453.1 Mb         for a in relevant_args
torchvision.transforms.functional normalize:281   :4453.1 Mb         mean = mean.view(-1, 1, 1)
torch.nn.modules.module _call_impl:749            :4453.1 Mb         return result
torch.nn.modules.module _call_impl:749            :4453.1 Mb         return result
models.stylegan2 forward:235                      :4433.1 Mb             out = F.conv_transpose2d(inputs, weight, padding=0, stride=2, groups=batch)
selectors close:270                               :8815.1 Mb         self._map = None
multiprocessing.queues _start_thread:170          :8815.1 Mb         self._thread.start()
torch.nn.modules.module _call_impl:728            :8815.1 Mb         for hook in itertools.chain(
torch.nn.modules.module _call_impl:749            :8815.1 Mb         return result
torch.utils.data._utils.collate default_collate:48:8815.1 Mb         out = None
torchvision.transforms.functional to_tensor:69    :8815.1 Mb     if isinstance(pic, np.ndarray):
dataset __getitem__:36                            :8815.1 Mb                 break
multiprocessing.queues get:103                    :8815.1 Mb                     timeout = deadline - time.monotonic()
models.stylegan2 forward:250                      :8797.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
torch.nn.modules.module _call_impl:718            :6613.1 Mb                 self._forward_pre_hooks.values()):
multiprocessing.connection recv_bytes:214         :6613.1 Mb         if maxlength is not None and maxlength < 0:
models.stylegan2 forward:250                      :2233.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
torchvision.transforms.transforms __call__:104    :2233.1 Mb         return F.to_tensor(pic)
threading start:852                               :2233.1 Mb             _start_new_thread(self._bootstrap, ())
dataset __getitem__:29                            :2233.1 Mb                 with self.env.begin(write=False) as txn:
torch.utils.data._utils.collate default_collate:53:2233.1 Mb             storage = elem.storage()._new_shared(numel)
multiprocessing.connection _poll:414              :2233.1 Mb         r = wait([self], timeout)
multiprocessing.connection recv_bytes:216         :2233.1 Mb         buf = self._recv_bytes(maxlength)
torch.nn.modules.module _call_impl:724            :2233.1 Mb         if torch._C._get_tracing_state():
torchvision.transforms.functional to_tensor:98    :2233.1 Mb     img = img.view(pic.size[1], pic.size[0], len(pic.getbands()))
dataset __getitem__:35                            :4463.1 Mb                 img = Image.open(buffer)
importlib._bootstrap _handle_fromlist:1021        :4463.1 Mb             if not isinstance(x, str):
selectors __init__:213                            :4463.1 Mb         self._map = _SelectorMapping(self)
multiprocessing.connection _recv:377              :4463.1 Mb         remaining = size
importlib._bootstrap _handle_fromlist:1019        :4463.1 Mb     if hasattr(module, '__path__'):
torchvision.transforms.functional _is_numpy:44    :4463.1 Mb     return isinstance(img, np.ndarray)
threading wait:551                                :4463.1 Mb             if not signaled:
torchvision.transforms.functional to_tensor:102   :4463.1 Mb         return img.float().div(255)
models.stylegan2 forward:235                      :4445.1 Mb             out = F.conv_transpose2d(inputs, weight, padding=0, stride=2, groups=batch)
multiprocessing.queues _start_thread:177          :6639.1 Mb                 exitpriority=-5
torchvision.transforms.functional normalize:265   :6639.1 Mb     if not isinstance(tensor, torch.Tensor):
torch.nn.modules.module _call_impl:727            :6639.1 Mb             result = self.forward(*input, **kwargs)
selectors _fileobj_lookup:225                     :6639.1 Mb             return _fileobj_to_fd(fileobj)
multiprocessing.connection _recv_bytes:409        :6639.1 Mb         if maxsize is not None and size > maxsize:
torch.overrides <genexpr>:1084                    :6639.1 Mb         type(a) is not torch.Tensor and
torchvision.transforms.functional to_tensor:98    :6639.1 Mb     img = img.view(pic.size[1], pic.size[0], len(pic.getbands()))
torch.utils.data._utils.collate default_collate:55:6639.1 Mb         return torch.stack(batch, 0, out=out)
models.stylegan2 forward:250                      :6621.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
multiprocessing.connection fileno:171             :4427.1 Mb         return self._handle
torch.nn.modules.module _call_impl:728            :4427.1 Mb         for hook in itertools.chain(
multiprocessing.connection _recv:379              :4427.1 Mb             chunk = read(handle, remaining)
models.stylegan2 forward:250                      :4427.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
multiprocessing.queues put:86                     :4427.1 Mb             if self._thread is None:
multiprocessing.util __init__:200                 :4427.1 Mb         self._key = (exitpriority, next(_finalizer_counter))
torchvision.transforms.functional normalize:278   :4427.1 Mb     if (std == 0).any():
torch.tensor <genexpr>:24                         :4427.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
importlib._bootstrap _handle_fromlist:1032        :4427.1 Mb             elif not hasattr(module, x):
selectors register:245                            :6621.1 Mb         return key
multiprocessing.queues _start_thread:183          :6621.1 Mb             [self._buffer, self._notempty],
torchvision.transforms.transforms __call__:66     :6621.1 Mb         for t in self.transforms:
multiprocessing.connection _recv:378              :6621.1 Mb         while remaining > 0:
multiprocessing.queues _start_thread:160          :6621.1 Mb         self._thread = threading.Thread(
torch.tensor <genexpr>:24                         :6621.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
torchvision.transforms.functional to_tensor:101   :6621.1 Mb     if isinstance(img, torch.ByteTensor):
torch.overrides <genexpr>:1087                    :6621.1 Mb         for a in relevant_args
models.stylegan2 forward:235                      :6621.1 Mb             out = F.conv_transpose2d(inputs, weight, padding=0, stride=2, groups=batch)
torch.tensor wrapped:24                           :4427.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
selectors select:422                              :4427.1 Mb             if event & ~self._EVENT_WRITE:
models.stylegan2 forward:250                      :4427.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
torch.nn.modules.module _call_impl:749            :4427.1 Mb         return result
torch.utils.data._utils.worker _worker_loop:169   :4427.1 Mb         while watchdog.is_alive():
threading __init__:500                            :4427.1 Mb         self._cond = Condition(Lock())
torch.utils.data._utils.fetch fetch:44            :4427.1 Mb             data = [self.dataset[idx] for idx in possibly_batched_index]
importlib._bootstrap _handle_fromlist:1044        :4427.1 Mb     return module
torch.tensor wrapped:26                           :4427.1 Mb         try:
threading __init__:238                            :6749.1 Mb         self._waiters = _deque()
multiprocessing.connection recv_bytes:212         :6749.1 Mb         self._check_closed()
torchvision.transforms.functional to_tensor:81    :6749.1 Mb     if accimage is not None and isinstance(pic, accimage.Image):
importlib._bootstrap _handle_fromlist:1019        :6749.1 Mb     if hasattr(module, '__path__'):
torchvision.transforms.functional normalize:285   :6749.1 Mb     return tensor
multiprocessing.connection poll:257               :6749.1 Mb         return self._poll(timeout)
torchvision.transforms.functional_pil _is_pil_image:16:6749.1 Mb     if accimage is not None:
torchvision.transforms.transforms forward:645     :6749.1 Mb         if torch.rand(1) < self.p:
models.stylegan2 forward:250                      :6749.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
models.stylegan2 forward:250                      :4427.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
importlib._bootstrap parent:420                   :4427.1 Mb             return self.name.rpartition('.')[0]
dataset __getitem__:27                            :4427.1 Mb         while True:
multiprocessing.connection _recv:378              :4427.1 Mb         while remaining > 0:
torch.overrides <genexpr>:1084                    :4427.1 Mb         type(a) is not torch.Tensor and
multiprocessing.connection wait:915               :4427.1 Mb                 selector.register(obj, selectors.EVENT_READ)
torchvision.transforms.transforms __call__:67     :4427.1 Mb             img = t(img)
threading is_set:509                              :4427.1 Mb         return self._flag
torch.utils.data._utils.collate default_collate:54:4427.1 Mb             out = elem.new(storage)
torch.nn.modules.module _call_impl:718            :9041.1 Mb                 self._forward_pre_hooks.values()):
selectors register:244                            :9041.1 Mb         self._fd_to_key[key.fd] = key
threading wait:550                                :9041.1 Mb             signaled = self._flag
multiprocessing.queues _start_thread:163          :9041.1 Mb                   self._wlock, self._writer.close, self._ignore_epipe,
torchvision.transforms.transforms forward:645     :9041.1 Mb         if torch.rand(1) < self.p:
multiprocessing.connection _recv:380              :9041.1 Mb             n = len(chunk)
torch.nn.modules.module _call_impl:717            :9041.1 Mb                 _global_forward_pre_hooks.values(),
torchvision.transforms.functional to_tensor:100   :9041.1 Mb     img = img.permute((2, 0, 1)).contiguous()
models.stylegan2 forward:250                      :9041.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
models.stylegan2 forward:250                      :4427.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
multiprocessing.connection wait:914               :4427.1 Mb             for obj in object_list:
multiprocessing.queues _start_thread:176          :4427.1 Mb                 [weakref.ref(self._thread)],
threading __init__:792                            :4427.1 Mb         self._kwargs = kwargs
torch.nn.modules.module _call_impl:727            :4427.1 Mb             result = self.forward(*input, **kwargs)
torch.overrides has_torch_function:1087           :4427.1 Mb         for a in relevant_args
multiprocessing.queues get:111                    :4427.1 Mb                 self._rlock.release()
torch.tensor <genexpr>:24                         :4427.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
torchvision.transforms.functional normalize:277   :4427.1 Mb     std = torch.as_tensor(std, dtype=dtype, device=tensor.device)
torch.tensor <genexpr>:24                         :6731.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
importlib._bootstrap _handle_fromlist:1021        :6731.1 Mb             if not isinstance(x, str):
multiprocessing.connection _recv:378              :6731.1 Mb         while remaining > 0:
torchvision.transforms.functional_pil _is_pil_image:16:6731.1 Mb     if accimage is not None:
torch.nn.modules.module _call_impl:734            :6731.1 Mb         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):
multiprocessing.queues _start_thread:171          :6731.1 Mb         debug('... done self._thread.start()')
torchvision.transforms.functional normalize:275   :6731.1 Mb     dtype = tensor.dtype
selectors __init__:211                            :6731.1 Mb         self._fd_to_key = {}
models.stylegan2 forward:250                      :6731.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
multiprocessing.util __init__:197                 :4427.1 Mb         self._callback = callback
models.stylegan2 forward:250                      :4427.1 Mb             out = F.conv2d(inputs, weight, padding=self.padding, groups=batch)
torchvision.transforms.transforms forward:647     :4427.1 Mb         return img
selectors _fileobj_lookup:224                     :4427.1 Mb         try:
importlib._bootstrap _handle_fromlist:1019        :4427.1 Mb     if hasattr(module, '__path__'):
multiprocessing.queues get:111                    :4427.1 Mb                 self._rlock.release()
torch.overrides has_torch_function:1084           :4427.1 Mb         type(a) is not torch.Tensor and
torch.utils.data._utils.worker _worker_loop:212   :4427.1 Mb             data_queue.put((idx, data))
torchvision.transforms.functional to_tensor:98    :4427.1 Mb     img = img.view(pic.size[1], pic.size[0], len(pic.getbands()))
torchvision.transforms.functional normalize:280   :6727.1 Mb     if mean.ndim == 1:
importlib._bootstrap _handle_fromlist:1019        :6727.1 Mb     if hasattr(module, '__path__'):
torchvision.transforms.functional to_tensor:98    :6727.1 Mb     img = img.view(pic.size[1], pic.size[0], len(pic.getbands()))
threading __init__:226                            :6727.1 Mb         try:
torch.nn.modules.module _call_impl:718            :6727.1 Mb                 self._forward_pre_hooks.values()):
torch.nn.modules.module _call_impl:728            :6727.1 Mb         for hook in itertools.chain(
selectors _key_from_fd:285                        :6727.1 Mb             return self._fd_to_key[fd]
multiprocessing.queues get:98                     :6727.1 Mb                 deadline = time.monotonic() + timeout
torch.nn.modules.module __getattr__:769           :6727.1 Mb                 return _parameters[name]
torch.nn.modules.module __getattr__:769           :4423.1 Mb                 return _parameters[name]
torch.tensor wrapped:27                           :4423.1 Mb             return f(*args, **kwargs)
dataset __getitem__:43                            :4423.1 Mb         return img
torchvision.transforms.functional to_tensor:81    :4423.1 Mb     if accimage is not None and isinstance(pic, accimage.Image):
threading __init__:800                            :4423.1 Mb         self._is_stopped = False
multiprocessing.connection recv_bytes:212         :4423.1 Mb         self._check_closed()
torch.overrides <genexpr>:1087                    :4423.1 Mb         for a in relevant_args
selectors __init__:211                            :4423.1 Mb         self._fd_to_key = {}
torchvision.transforms.functional normalize:272   :4423.1 Mb     if not inplace:
torch.utils.data._utils.collate default_collate:48:9033.1 Mb         out = None
torchvision.transforms.transforms forward:647     :9033.1 Mb         return img
multiprocessing.queues _start_thread:167          :9033.1 Mb         self._thread.daemon = True
multiprocessing.connection _recv_bytes:407        :9033.1 Mb         buf = self._recv(4)
torchvision.transforms.transforms __call__:66     :9033.1 Mb         for t in self.transforms:
multiprocessing.connection wait:915               :9033.1 Mb                 selector.register(obj, selectors.EVENT_READ)
torch.tensor wrapped:23                           :9033.1 Mb         from torch.overrides import has_torch_function, handle_torch_function
torchvision.transforms.functional to_tensor:98    :9033.1 Mb     img = img.view(pic.size[1], pic.size[0], len(pic.getbands()))
torch.nn.modules.module __getattr__:769           :9033.1 Mb                 return _parameters[name]
torch.nn.modules.module __getattr__:769           :4423.1 Mb                 return _parameters[name]
torch.overrides <genexpr>:1084                    :4423.1 Mb         type(a) is not torch.Tensor and
torch.nn.modules.module _call_impl:727            :4423.1 Mb             result = self.forward(*input, **kwargs)
torch.tensor wrapped:24                           :4423.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
torchvision.transforms.transforms forward:226     :4423.1 Mb         return F.normalize(tensor, self.mean, self.std, self.inplace)
multiprocessing.connection _recv_bytes:408        :4423.1 Mb         size, = struct.unpack("!i", buf.getvalue())
threading start:850                               :4423.1 Mb             _limbo[self] = self
importlib._bootstrap _handle_fromlist:1028        :4423.1 Mb             elif x == '*':
selectors _fileobj_to_fd:41                       :4423.1 Mb     if fd < 0:
torch.overrides has_torch_function:1087           :6733.1 Mb         for a in relevant_args
torchvision.transforms.functional normalize:280   :6733.1 Mb     if mean.ndim == 1:
torch.tensor wrapped:24                           :6733.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
selectors register:353                            :6733.1 Mb         poller_events = 0
multiprocessing.connection _recv:377              :6733.1 Mb         remaining = size
threading __enter__:241                           :6733.1 Mb         return self._lock.__enter__()
torch.storage _new_shared:134                     :6733.1 Mb         elif get_sharing_strategy() == 'file_system':
torchvision.transforms.functional normalize:275   :6733.1 Mb     dtype = tensor.dtype
torch.nn.modules.module __getattr__:769           :6733.1 Mb                 return _parameters[name]
torch.nn.modules.module __getattr__:769           :4425.1 Mb                 return _parameters[name]
multiprocessing.queues get:111                    :4425.1 Mb                 self._rlock.release()
selectors select:405                              :4425.1 Mb         if timeout is None:
torch.tensor wrapped:27                           :4425.1 Mb             return f(*args, **kwargs)
multiprocessing.util __init__:187                 :4425.1 Mb         if (exitpriority is not None) and not isinstance(exitpriority,int):
torchvision.transforms.transforms __call__:68     :4425.1 Mb         return img
torchvision.transforms.functional_pil _is_pil_image:19:4425.1 Mb         return isinstance(img, Image.Image)
multiprocessing.queues _start_thread:156          :4425.1 Mb         debug('Queue._start_thread()')
torch.overrides has_torch_function:1087           :4425.1 Mb         for a in relevant_args
multiprocessing.util __init__:193                 :5587.1 Mb             self._weakref = weakref.ref(obj, self)
torch.utils.data._utils.fetch <listcomp>:44       :5587.1 Mb             data = [self.dataset[idx] for idx in possibly_batched_index]
multiprocessing.queues _start_thread:159          :5587.1 Mb         self._buffer.clear()
torch.overrides <genexpr>:1087                    :5587.1 Mb         for a in relevant_args
torch.utils.data._utils.worker _worker_loop:182   :5587.1 Mb             elif r is None:
selectors select:413                              :5587.1 Mb         ready = []
torch.nn.modules.module _call_impl:729            :5587.1 Mb                 _global_forward_hooks.values(),
torch.nn.modules.module _call_impl:728            :5587.1 Mb         for hook in itertools.chain(
torch.nn.modules.module __getattr__:769           :5587.1 Mb                 return _parameters[name]
threading __init__:796                            :6693.1 Mb             self._daemonic = current_thread().daemon
torch.nn.modules.module _call_impl:734            :6693.1 Mb         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):
torch.nn.modules.module _call_impl:724            :6693.1 Mb         if torch._C._get_tracing_state():
torch.utils.data._utils.fetch <listcomp>:44       :6693.1 Mb             data = [self.dataset[idx] for idx in possibly_batched_index]
torchvision.transforms.functional to_tensor:81    :6693.1 Mb     if accimage is not None and isinstance(pic, accimage.Image):
torchvision.transforms.functional to_tensor:89    :6693.1 Mb     elif pic.mode == 'I;16':
multiprocessing.connection wait:922               :6693.1 Mb                 if ready:
multiprocessing.util __init__:199                 :6693.1 Mb         self._kwargs = kwargs or {}
torch.nn.modules.module __getattr__:769           :6693.1 Mb                 return _parameters[name]
torch.nn.modules.module __getattr__:769           :5589.1 Mb                 return _parameters[name]
multiprocessing.connection recv_bytes:216         :5589.1 Mb         buf = self._recv_bytes(maxlength)
torch.overrides <genexpr>:1087                    :5589.1 Mb         for a in relevant_args
torch.utils.data._utils.collate <listcomp>:52     :5589.1 Mb             numel = sum([x.numel() for x in batch])
torch.nn.modules.module _call_impl:724            :5589.1 Mb         if torch._C._get_tracing_state():
torch.nn.modules.module _call_impl:718            :5589.1 Mb                 self._forward_pre_hooks.values()):
torch.utils.data._utils.worker _worker_loop:213   :5589.1 Mb             del data, idx, index, r  # save memory
torch.nn.modules.module _call_impl:718            :5589.1 Mb                 self._forward_pre_hooks.values()):
threading __init__:230                            :5589.1 Mb         try:
threading __init__:231                            :6695.1 Mb             self._acquire_restore = lock._acquire_restore
torch.utils.data._utils.collate default_collate:53:6695.1 Mb             storage = elem.storage()._new_shared(numel)
multiprocessing.connection _recv:375              :6695.1 Mb         buf = io.BytesIO()
torch.tensor wrapped:26                           :6695.1 Mb         try:
torchvision.transforms.transforms forward:226     :6695.1 Mb         return F.normalize(tensor, self.mean, self.std, self.inplace)
torch.nn.modules.module _call_impl:727            :6695.1 Mb             result = self.forward(*input, **kwargs)
torch.utils.data._utils.worker is_alive:55        :6695.1 Mb             if not self.manager_dead:
torch.nn.modules.module _call_impl:727            :6695.1 Mb             result = self.forward(*input, **kwargs)
torch.nn.modules.module __getattr__:769           :6695.1 Mb                 return _parameters[name]
torch.nn.modules.module __getattr__:769           :5593.1 Mb                 return _parameters[name]
torch.tensor wrapped:23                           :5593.1 Mb         from torch.overrides import has_torch_function, handle_torch_function
torch.nn.modules.module _call_impl:716            :5593.1 Mb         for hook in itertools.chain(
threading __init__:804                            :5593.1 Mb         self._stderr = _sys.stderr
torch.overrides has_torch_function:1087           :5593.1 Mb         for a in relevant_args
multiprocessing.connection _recv_bytes:408        :5593.1 Mb         size, = struct.unpack("!i", buf.getvalue())
torch.multiprocessing get_sharing_strategy:70     :5593.1 Mb     return _sharing_strategy
importlib._bootstrap _handle_fromlist:1044        :5593.1 Mb     return module
multiprocessing.queues get:103                    :5593.1 Mb                     timeout = deadline - time.monotonic()
torch.nn.modules.module _call_impl:717            :7787.1 Mb                 _global_forward_pre_hooks.values(),
threading __init__:806                            :7787.1 Mb         _dangling.add(self)
torch.overrides <genexpr>:1084                    :7787.1 Mb         type(a) is not torch.Tensor and
multiprocessing.connection _recv_bytes:409        :7787.1 Mb         if maxsize is not None and size > maxsize:
torch.storage _new_shared:137                     :7787.1 Mb             return cls._new_using_fd(size)
torch.tensor wrapped:24                           :7787.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
multiprocessing.queues get:104                    :7787.1 Mb                     if not self._poll(timeout):
importlib._bootstrap _handle_fromlist:1044        :7787.1 Mb     return module
torch.nn.modules.module __getattr__:769           :7787.1 Mb                 return _parameters[name]
torch.nn.modules.module __getattr__:769           :5595.1 Mb                 return _parameters[name]
torch.nn.modules.module _call_impl:730            :5595.1 Mb                 self._forward_hooks.values()):
multiprocessing.connection _recv:387              :5595.1 Mb             remaining -= n
torch.overrides <genexpr>:1084                    :5595.1 Mb         type(a) is not torch.Tensor and
selectors __init__:213                            :5595.1 Mb         self._map = _SelectorMapping(self)
multiprocessing.queues _start_thread:156          :5595.1 Mb         debug('Queue._start_thread()')
torch.overrides <genexpr>:1087                    :5595.1 Mb         for a in relevant_args
torch.overrides has_torch_function:1083           :5595.1 Mb     return _is_torch_function_enabled() and any(
threading start:844                               :5595.1 Mb         if not self._initialized:
torch.tensor wrapped:27                           :6693.1 Mb             return f(*args, **kwargs)
selectors __init__:349                            :6693.1 Mb         self._selector = self._selector_cls()
multiprocessing.queues _start_thread:159          :6693.1 Mb         self._buffer.clear()
torch.tensor wrapped:26                           :6693.1 Mb         try:
torch.overrides has_torch_function:1087           :6693.1 Mb         for a in relevant_args
threading is_set:509                              :6693.1 Mb         return self._flag
torchvision.transforms.transforms __call__:66     :6693.1 Mb         for t in self.transforms:
multiprocessing.connection recv_bytes:217         :6693.1 Mb         if buf is None:
torch.nn.modules.module __getattr__:769           :6693.1 Mb                 return _parameters[name]
torch.nn.modules.module __getattr__:769           :5597.1 Mb                 return _parameters[name]
torch.nn.modules.module _call_impl:728            :5597.1 Mb         for hook in itertools.chain(
torch.tensor wrapped:23                           :5597.1 Mb         from torch.overrides import has_torch_function, handle_torch_function
torchvision.transforms.transforms forward:617     :5597.1 Mb         return img
threading wait:550                                :5597.1 Mb             signaled = self._flag
multiprocessing.synchronize is_set:328            :5597.1 Mb         with self._cond:
torch.nn.modules.module _call_impl:730            :5597.1 Mb                 self._forward_hooks.values()):
selectors _fileobj_to_fd:33                       :5597.1 Mb     if isinstance(fileobj, int):
threading __init__:788                            :5597.1 Mb             kwargs = {}
importlib._bootstrap _handle_fromlist:1019        :6697.1 Mb     if hasattr(module, '__path__'):
torch.nn.modules.module _call_impl:728            :6697.1 Mb         for hook in itertools.chain(
threading wait:551                                :6697.1 Mb             if not signaled:
multiprocessing.synchronize __enter__:230         :6697.1 Mb         return self._lock.__enter__()
torch.nn.modules.module _call_impl:734            :6697.1 Mb         if (len(self._backward_hooks) > 0) or (len(_global_backward_hooks) > 0):
selectors _fileobj_to_fd:36                       :6697.1 Mb         try:
threading __init__:789                            :6697.1 Mb         self._target = target
torch.nn.modules.module __getattr__:769           :6697.1 Mb                 return _parameters[name]
torch.nn.modules.module _call_impl:730            :6697.1 Mb                 self._forward_hooks.values()):
models.stylegan2 forward:633                      :6955.1 Mb             out = (out + skip) / math.sqrt(2)
multiprocessing.queues get:97                     :6955.1 Mb             if block:
torch.overrides has_torch_function:1083           :6955.1 Mb     return _is_torch_function_enabled() and any(
multiprocessing.queues _start_thread:171          :6955.1 Mb         debug('... done self._thread.start()')
torch.tensor wrapped:23                           :6955.1 Mb         from torch.overrides import has_torch_function, handle_torch_function
multiprocessing.connection poll:257               :6955.1 Mb         return self._poll(timeout)
torchvision.transforms.functional normalize:282   :6955.1 Mb     if std.ndim == 1:
multiprocessing.connection _recv:380              :6955.1 Mb             n = len(chunk)
torchvision.transforms.functional normalize:276   :6955.1 Mb     mean = torch.as_tensor(mean, dtype=dtype, device=tensor.device)
selectors register:240                            :8151.1 Mb         if key.fd in self._fd_to_key:
multiprocessing.queues get:111                    :8151.1 Mb                 self._rlock.release()
selectors register:238                            :8151.1 Mb         key = SelectorKey(fileobj, self._fileobj_lookup(fileobj), events, data)
multiprocessing.util __init__:198                 :8151.1 Mb         self._args = args
torchvision.transforms.functional normalize:285   :8151.1 Mb     return tensor
torchvision.transforms.transforms __call__:104    :8151.1 Mb         return F.to_tensor(pic)
torch.utils.data._utils.collate default_collate:53:8151.1 Mb             storage = elem.storage()._new_shared(numel)
torchvision.transforms.transforms __call__:104    :8125.1 Mb         return F.to_tensor(pic)
selectors register:244                            :7027.1 Mb         self._fd_to_key[key.fd] = key
multiprocessing.queues get:113                    :7027.1 Mb         return _ForkingPickler.loads(res)
selectors _fileobj_lookup:224                     :7027.1 Mb         try:
torch.nn.modules.module _call_impl:728            :7027.1 Mb         for hook in itertools.chain(
multiprocessing.util __init__:199                 :7027.1 Mb         self._kwargs = kwargs or {}
torchvision.transforms.functional to_tensor:63    :7027.1 Mb     if not(F_pil._is_pil_image(pic) or _is_numpy(pic)):
torch.storage _new_shared:131                     :7027.1 Mb         from torch.multiprocessing import get_sharing_strategy
selectors register:245                            :8125.1 Mb         return key
selectors _fileobj_lookup:225                     :8125.1 Mb             return _fileobj_to_fd(fileobj)
torch.utils.data._utils.worker _worker_loop:174   :8125.1 Mb             if isinstance(r, _ResumeIteration):
torch.nn.modules.module _call_impl:729            :8125.1 Mb                 _global_forward_hooks.values(),
torchvision.transforms.functional_pil _is_pil_image:16:8125.1 Mb     if accimage is not None:
multiprocessing.util __init__:200                 :8125.1 Mb         self._key = (exitpriority, next(_finalizer_counter))
importlib._bootstrap _handle_fromlist:1019        :8125.1 Mb     if hasattr(module, '__path__'):
selectors register:355                            :10319.1Mb             poller_events |= self._EVENT_READ
selectors _fileobj_to_fd:37                       :10319.1Mb             fd = int(fileobj.fileno())
multiprocessing.synchronize is_set:328            :10319.1Mb         with self._cond:
torch.nn.modules.module _call_impl:749            :10319.1Mb         return result
torchvision.transforms.functional _is_numpy:44    :10319.1Mb     return isinstance(img, np.ndarray)
multiprocessing.queues put:88                     :10319.1Mb             self._buffer.append(obj)
importlib._bootstrap _handle_fromlist:1028        :10319.1Mb             elif x == '*':
torchvision.transforms.functional _is_numpy:44    :10319.1Mb     return isinstance(img, np.ndarray)
selectors register:356                            :9221.1 Mb         if events & EVENT_WRITE:
multiprocessing.connection fileno:170             :9221.1 Mb         self._check_closed()
torchvision.transforms.transforms __call__:66     :9221.1 Mb         for t in self.transforms:
multiprocessing.queues put:89                     :9221.1 Mb             self._notempty.notify()
multiprocessing.synchronize __enter__:230         :9221.1 Mb         return self._lock.__enter__()
torchvision.transforms.functional to_tensor:69    :9221.1 Mb     if isinstance(pic, np.ndarray):
importlib._bootstrap _handle_fromlist:1032        :9221.1 Mb             elif not hasattr(module, x):
torchvision.transforms.functional to_tensor:69    :9221.1 Mb     if isinstance(pic, np.ndarray):
threading notify:345                              :7027.1 Mb         if not self._is_owned():
torchvision.transforms.transforms __call__:68     :7027.1 Mb         return img
torchvision.transforms.functional to_tensor:81    :7027.1 Mb     if accimage is not None and isinstance(pic, accimage.Image):
importlib._bootstrap _handle_fromlist:1020        :7027.1 Mb         for x in fromlist:
multiprocessing.synchronize __enter__:95          :7027.1 Mb         return self._semlock.__enter__()
torchvision.transforms.functional to_tensor:81    :7027.1 Mb     if accimage is not None and isinstance(pic, accimage.Image):
selectors register:359                            :7027.1 Mb             self._selector.register(key.fd, poller_events)
multiprocessing.connection fileno:171             :8131.1 Mb         return self._handle
threading _is_owned:258                           :8131.1 Mb         if self._lock.acquire(0):
importlib._bootstrap _handle_fromlist:1044        :8131.1 Mb     return module
dataset __getitem__:43                            :8131.1 Mb         return img
torchvision.transforms.functional to_tensor:87    :8131.1 Mb     if pic.mode == 'I':
multiprocessing.synchronize is_set:329            :8131.1 Mb             if self._flag.acquire(False):
selectors register:363                            :8131.1 Mb         return key
torchvision.transforms.functional to_tensor:87    :8131.1 Mb     if pic.mode == 'I':
selectors register:244                            :9235.1 Mb         self._fd_to_key[key.fd] = key
threading notify:349                              :9235.1 Mb         if not waiters_to_notify:
torch.storage _new_shared:137                     :9235.1 Mb             return cls._new_using_fd(size)
dataset __getitem__:29                            :9235.1 Mb                 with self.env.begin(write=False) as txn:
torchvision.transforms.functional to_tensor:96    :9235.1 Mb         img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))
multiprocessing.connection wait:920               :9235.1 Mb             while True:
torchvision.transforms.functional to_tensor:96    :9235.1 Mb         img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))
torch.utils.data._utils.worker _worker_loop:191   :9235.1 Mb             idx, index = r
dataset __getitem__:32                            :8129.1 Mb                     img_bytes = txn.get(key)
selectors select:405                              :8129.1 Mb         if timeout is None:
torch.utils.data._utils.worker _worker_loop:197   :8129.1 Mb                 try:
torch.utils.data._utils.collate default_collate:55:8129.1 Mb         return torch.stack(batch, 0, out=out)
torchvision.transforms.functional to_tensor:100   :8129.1 Mb     img = img.permute((2, 0, 1)).contiguous()
torchvision.transforms.functional to_tensor:98    :8129.1 Mb     img = img.view(pic.size[1], pic.size[0], len(pic.getbands()))
selectors register:354                            :8129.1 Mb         if events & EVENT_READ:
torch.utils.data._utils.worker _worker_loop:213   :8129.1 Mb             del data, idx, index, r  # save memory
multiprocessing.connection wait:917               :9241.1 Mb             if timeout is not None:
torch.nn.modules.module _call_impl:716            :9241.1 Mb         for hook in itertools.chain(
multiprocessing.queues get:92                     :9241.1 Mb         if block and timeout is None:
torch.nn.modules.module _call_impl:717            :9241.1 Mb                 _global_forward_pre_hooks.values(),
dataset __getitem__:30                            :9241.1 Mb                     key = f"{self.resolution}-{str(index).zfill(5)}".encode("utf-8")
multiprocessing.queues put:89                     :9241.1 Mb             self._notempty.notify()
torch.nn.modules.module _call_impl:724            :9241.1 Mb         if torch._C._get_tracing_state():
selectors select:420                              :9241.1 Mb             if event & ~self._EVENT_READ:
dataset __getitem__:34                            :8103.1 Mb                 buffer = BytesIO(img_bytes)
threading _is_owned:258                           :8103.1 Mb         if self._lock.acquire(0):
torchvision.transforms.transforms forward:226     :8103.1 Mb         return F.normalize(tensor, self.mean, self.std, self.inplace)
selectors select:423                              :8103.1 Mb                 events |= EVENT_READ
multiprocessing.queues get:99                     :8103.1 Mb             if not self._rlock.acquire(block, timeout):
multiprocessing.connection wait:921               :8103.1 Mb                 ready = selector.select(timeout)
torch.nn.modules.module _call_impl:724            :8103.1 Mb         if torch._C._get_tracing_state():
torch.nn.modules.module _call_impl:727            :8103.1 Mb             result = self.forward(*input, **kwargs)
threading notify:352                              :10313.1Mb             waiter.release()
torchvision.transforms.functional normalize:276   :10313.1Mb     mean = torch.as_tensor(mean, dtype=dtype, device=tensor.device)
selectors select:418                              :10313.1Mb         for fd, event in fd_event_list:
multiprocessing.connection _check_closed:135      :10313.1Mb         if self._handle is None:
torch.tensor <genexpr>:24                         :10313.1Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
torch.nn.modules.module _call_impl:716            :10313.1Mb         for hook in itertools.chain(
selectors select:415                              :10313.1Mb             fd_event_list = self._selector.poll(timeout)
torchvision.transforms.functional normalize:273   :10313.1Mb         tensor = tensor.clone()
torchvision.transforms.functional normalize:277   :8005.1 Mb     std = torch.as_tensor(std, dtype=dtype, device=tensor.device)
selectors select:420                              :8005.1 Mb             if event & ~self._EVENT_READ:
torch.nn.modules.module _call_impl:724            :8005.1 Mb         if torch._C._get_tracing_state():
threading __exit__:244                            :8005.1 Mb         return self._lock.__exit__(*args)
importlib._bootstrap _handle_fromlist:1019        :8005.1 Mb     if hasattr(module, '__path__'):
multiprocessing.connection <listcomp>:923         :8005.1 Mb                     return [key.fileobj for (key, events) in ready]
torch.overrides has_torch_function:1087           :6843.1 Mb         for a in relevant_args
multiprocessing.connection _poll:414              :6843.1 Mb         r = wait([self], timeout)
torchvision.transforms.functional normalize:278   :6843.1 Mb     if (std == 0).any():
selectors select:422                              :6843.1 Mb             if event & ~self._EVENT_WRITE:
torch.nn.modules.module _call_impl:727            :6843.1 Mb             result = self.forward(*input, **kwargs)
importlib._bootstrap _handle_fromlist:1044        :6843.1 Mb     return module
multiprocessing.connection <listcomp>:923         :6843.1 Mb                     return [key.fileobj for (key, events) in ready]
torch.utils.data._utils.worker _worker_loop:213   :6843.1 Mb             del data, idx, index, r  # save memory
selectors register:352                            :7549.1 Mb         key = super().register(fileobj, events, data)
torch.nn.modules.module _call_impl:729            :7549.1 Mb                 _global_forward_hooks.values(),
multiprocessing.queues get:98                     :7549.1 Mb                 deadline = time.monotonic() + timeout
torch.overrides <genexpr>:1084                    :7549.1 Mb         type(a) is not torch.Tensor and
torch.overrides has_torch_function:1087           :7549.1 Mb         for a in relevant_args
torch.overrides <genexpr>:1084                    :7549.1 Mb         type(a) is not torch.Tensor and
multiprocessing.connection wait:923               :7549.1 Mb                     return [key.fileobj for (key, events) in ready]
multiprocessing.connection recv_bytes:214         :7549.1 Mb         if maxlength is not None and maxlength < 0:
selectors _fileobj_lookup:224                     :6971.1 Mb         try:
torch.nn.modules.module _call_impl:749            :6971.1 Mb         return result
multiprocessing.queues get:102                    :6971.1 Mb                 if block:
torch.overrides <genexpr>:1087                    :6971.1 Mb         for a in relevant_args
torch.tensor wrapped:26                           :6971.1 Mb         try:
torch.overrides <genexpr>:1084                    :6971.1 Mb         type(a) is not torch.Tensor and
multiprocessing.connection _recv:375              :6971.1 Mb         buf = io.BytesIO()
selectors __exit__:203                            :6971.1 Mb         self.close()
dataset __getitem__:34                            :7997.1 Mb                 buffer = BytesIO(img_bytes)
torch.tensor wrapped:27                           :7997.1 Mb             return f(*args, **kwargs)
torch.utils.data._utils.collate default_collate:52:7997.1 Mb             numel = sum([x.numel() for x in batch])
selectors _fileobj_to_fd:36                       :7997.1 Mb         try:
multiprocessing.connection _recv:388              :7997.1 Mb         return buf
torch.tensor <genexpr>:24                         :7997.1 Mb         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
multiprocessing.connection _recv_bytes:409        :7997.1 Mb         if maxsize is not None and size > maxsize:
selectors select:405                              :7997.1 Mb         if timeout is None:
selectors _fileobj_to_fd:41                       :6845.1 Mb     if fd < 0:
torch.storage _new_shared:131                     :6845.1 Mb         from torch.multiprocessing import get_sharing_strategy
multiprocessing.queues get:113                    :6845.1 Mb         return _ForkingPickler.loads(res)
torch.overrides <genexpr>:1087                    :6845.1 Mb         for a in relevant_args
multiprocessing.connection _recv:378              :6845.1 Mb         while remaining > 0:
selectors select:415                              :6845.1 Mb             fd_event_list = self._selector.poll(timeout)
torchvision.transforms.functional_pil _is_pil_image:19:6845.1 Mb         return isinstance(img, Image.Image)
torch.nn.modules.module _call_impl:716            :6845.1 Mb         for hook in itertools.chain(
importlib._bootstrap _handle_fromlist:1044        :7117.1 Mb     return module
importlib._bootstrap _handle_fromlist:1032        :7117.1 Mb             elif not hasattr(module, x):
torchvision.transforms.functional normalize:278   :7117.1 Mb     if (std == 0).any():
selectors select:414                              :7117.1 Mb         try:
torchvision.transforms.functional to_tensor:100   :7117.1 Mb     img = img.permute((2, 0, 1)).contiguous()
torch.tensor wrapped:27                           :7867.1 Mb             return f(*args, **kwargs)
torchvision.transforms.functional normalize:275   :7867.1 Mb     dtype = tensor.dtype
threading notify:345                              :7867.1 Mb         if not self._is_owned():
multiprocessing.queues put:88                     :7867.1 Mb             self._buffer.append(obj)
torch.autograd backward:132                       :7867.1 Mb         allow_unreachable=True)  # allow_unreachable flag
selectors select:415                              :7867.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7867.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7867.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7867.1 Mb             fd_event_list = self._selector.poll(timeout)
multiprocessing.queues get:101                    :7579.1 Mb             try:
selectors select:422                              :7579.1 Mb             if event & ~self._EVENT_WRITE:
multiprocessing.queues get:101                    :7353.1 Mb             try:
threading notify:354                              :6253.1 Mb                 all_waiters.remove(waiter)
multiprocessing.queues get:102                    :6253.1 Mb                 if block:
selectors select:423                              :6253.1 Mb                 events |= EVENT_READ
multiprocessing.queues get:102                    :6247.1 Mb                 if block:
torch.nn.modules.module __getattr__:769           :6235.1 Mb                 return _parameters[name]
selectors select:415                              :6235.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :6235.1 Mb             fd_event_list = self._selector.poll(timeout)
multiprocessing.connection wait:913               :6503.1 Mb         with _WaitSelector() as selector:
multiprocessing.queues get:92                     :6503.1 Mb         if block and timeout is None:
torch.utils.data._utils.worker _worker_loop:186   :6759.1 Mb             elif done_event.is_set() or iteration_end:
multiprocessing.connection wait:914               :6759.1 Mb             for obj in object_list:
torch.autograd grad:204                           :6501.1 Mb         inputs, allow_unused)
torch.utils.data._utils.fetch fetch:43            :6501.1 Mb         if self.auto_collation:
torchvision.transforms.functional normalize:275   :9317.1 Mb     dtype = tensor.dtype
torch.utils.data._utils.worker _worker_loop:169   :6757.1 Mb         while watchdog.is_alive():
selectors _fileobj_to_fd:37                       :7909.1 Mb             fd = int(fileobj.fileno())
selectors register:353                            :6757.1 Mb         poller_events = 0
selectors select:415                              :8685.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:428                              :6505.1 Mb         return ready
torch.autograd grad:204                           :6761.1 Mb         inputs, allow_unused)
selectors register:359                            :7019.1 Mb             self._selector.register(key.fd, poller_events)
torch.autograd backward:132                       :7019.1 Mb         allow_unreachable=True)  # allow_unreachable flag
selectors select:415                              :7019.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7019.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7019.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7019.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7019.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7275.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :7275.1 Mb             fd_event_list = self._selector.poll(timeout)
torch.nn.modules.module __getattr__:769           :7277.1 Mb                 return _parameters[name]
selectors register:363                            :7277.1 Mb         return key
selectors select:415                              :8805.1 Mb             fd_event_list = self._selector.poll(timeout)
multiprocessing.connection wait:925               :6483.1 Mb                     if timeout is not None:
torch.utils.data._utils.worker _worker_loop:170   :8677.1 Mb             try:
selectors select:415                              :8677.1 Mb             fd_event_list = self._selector.poll(timeout)
multiprocessing.connection wait:914               :6483.1 Mb             for obj in object_list:
selectors select:428                              :6483.1 Mb         return ready
multiprocessing.connection wait:922               :8677.1 Mb                 if ready:
selectors register:352                            :8677.1 Mb         key = super().register(fileobj, events, data)
selectors select:415                              :8677.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8677.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors _fileobj_to_fd:37                       :6485.1 Mb             fd = int(fileobj.fileno())
multiprocessing.connection wait:927               :6485.1 Mb                         if timeout < 0:
selectors close:270                               :6485.1 Mb         self._map = None
multiprocessing.connection wait:925               :6485.1 Mb                     if timeout is not None:
multiprocessing.connection wait:926               :10865.1Mb                         timeout = deadline - time.monotonic()
multiprocessing.connection _poll:415              :10865.1Mb         return bool(r)
multiprocessing.connection wait:928               :10865.1Mb                             return ready
multiprocessing.connection _check_closed:135      :10865.1Mb         if self._handle is None:
selectors register:240                            :6485.1 Mb         if key.fd in self._fd_to_key:
selectors close:269                               :6485.1 Mb         self._fd_to_key.clear()
multiprocessing.connection _poll:415              :6485.1 Mb         return bool(r)
torch.utils.data._utils.worker _worker_loop:173   :6485.1 Mb                 continue
selectors register:244                            :8671.1 Mb         self._fd_to_key[key.fd] = key
selectors close:270                               :8671.1 Mb         self._map = None
torch.utils.data._utils.worker _worker_loop:169   :8671.1 Mb         while watchdog.is_alive():
multiprocessing.queues get:105                    :8671.1 Mb                         raise Empty
torch.utils.data._utils.worker _worker_loop:172   :6485.1 Mb             except queue.Empty:
torch.utils.data._utils.worker _worker_loop:173   :8671.1 Mb                 continue
torch.utils.data._utils.worker is_alive:57        :6485.1 Mb             return not self.manager_dead
multiprocessing.connection wait:914               :6485.1 Mb             for obj in object_list:
torch.utils.data._utils.worker _worker_loop:170   :8671.1 Mb             try:
multiprocessing.connection wait:917               :8671.1 Mb             if timeout is not None:
multiprocessing.connection wait:918               :6485.1 Mb                 deadline = time.monotonic() + timeout
torch.utils.data._utils.worker _worker_loop:171   :6485.1 Mb                 r = index_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
multiprocessing.queues get:99                     :6485.1 Mb             if not self._rlock.acquire(block, timeout):
torch.utils.data._utils.worker _worker_loop:170   :6485.1 Mb             try:
torch.autograd backward:132                       :6485.1 Mb         allow_unreachable=True)  # allow_unreachable flag
selectors select:415                              :6509.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :6735.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :6735.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :6735.1 Mb             fd_event_list = self._selector.poll(timeout)
op.upfirdn2d forward:119                          :6863.1 Mb             input, kernel, up_x, up_y, down_x, down_y, pad_x0, pad_x1, pad_y0, pad_y1
torch.nn.modules.module _call_impl:718            :7057.1 Mb                 self._forward_pre_hooks.values()):
op.upfirdn2d forward:119                          :7121.1 Mb             input, kernel, up_x, up_y, down_x, down_y, pad_x0, pad_x1, pad_y0, pad_y1
torch.overrides has_torch_function:1084           :7355.1 Mb         type(a) is not torch.Tensor and
torch.nn.modules.module __getattr__:769           :7381.1 Mb                 return _parameters[name]
selectors select:415                              :7407.1 Mb             fd_event_list = self._selector.poll(timeout)
multiprocessing.connection wait:927               :8083.1 Mb                         if timeout < 0:
torchvision.transforms.transforms __call__:66     :8083.1 Mb         for t in self.transforms:
torch.autograd backward:132                       :8083.1 Mb         allow_unreachable=True)  # allow_unreachable flag
selectors select:415                              :8083.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8083.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8083.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8083.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8083.1 Mb             fd_event_list = self._selector.poll(timeout)
selectors select:415                              :8083.1 Mb             fd_event_list = self._selector.poll(timeout)
